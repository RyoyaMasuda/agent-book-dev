{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraphで作るAIエージェント実践入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 ハンズオン：Q&Aアプリケーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.0\n",
      "  Using cached langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
      "Collecting langchain-openai==0.2.0\n",
      "  Using cached langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
      "Collecting langgraph==0.2.22\n",
      "  Using cached langgraph-0.2.22-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (3.11.13)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (2.0.39)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (8.5.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (0.1.147)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0\n",
      "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (2.10.6)\n",
      "Collecting langchain-core<0.4.0,>=0.3.0\n",
      "  Downloading langchain_core-0.3.47-py3-none-any.whl (417 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.1/417.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-openai==0.2.0) (0.9.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-openai==0.2.0) (1.55.3)\n",
      "Collecting langgraph-checkpoint<2.0.0,>=1.0.2\n",
      "  Using cached langgraph_checkpoint-1.0.12-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.18.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (2.6.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (24.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (4.12.2)\n",
      "Collecting msgpack<2.0.0,>=1.1.0\n",
      "  Using cached msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (3.10.15)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.28.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.8.0)\n",
      "Requirement already satisfied: sniffio in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (2.27.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.0) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (3.0.0)\n",
      "Installing collected packages: msgpack, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph, langchain\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.30\n",
      "    Uninstalling langchain-core-0.2.30:\n",
      "      Successfully uninstalled langchain-core-0.2.30\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.2.2\n",
      "    Uninstalling langchain-text-splitters-0.2.2:\n",
      "      Successfully uninstalled langchain-text-splitters-0.2.2\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.1.21\n",
      "    Uninstalling langchain-openai-0.1.21:\n",
      "      Successfully uninstalled langchain-openai-0.1.21\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.2.13\n",
      "    Uninstalling langchain-0.2.13:\n",
      "      Successfully uninstalled langchain-0.2.13\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-experimental 0.3.4 requires langchain-community<0.4.0,>=0.3.0, but you have langchain-community 0.2.12 which is incompatible.\n",
      "langchain-community 0.2.12 requires langchain<0.3.0,>=0.2.13, but you have langchain 0.3.0 which is incompatible.\n",
      "langchain-community 0.2.12 requires langchain-core<0.3.0,>=0.2.30, but you have langchain-core 0.3.47 which is incompatible.\n",
      "langchain-chroma 0.1.2 requires langchain-core<0.3,>=0.1.40, but you have langchain-core 0.3.47 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-0.3.0 langchain-core-0.3.47 langchain-openai-0.2.0 langchain-text-splitters-0.3.7 langgraph-0.2.22 langgraph-checkpoint-1.0.12 msgpack-1.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain==0.3.0 langchain-openai==0.2.0 langgraph==0.2.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from google.colab import userdata\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLES = {\n",
    "    \"1\": {\n",
    "        \"name\": \"一般知識エキスパート\",\n",
    "        \"description\": \"幅広い分野の一般的な質問に答える\",\n",
    "        \"details\": \"幅広い分野の一般的な質問に対して、正確で分かりやすい回答を提供してください。\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"name\": \"生成AI製品エキスパート\",\n",
    "        \"description\": \"生成AIや関連製品、技術に関する専門的な質問に答える\",\n",
    "        \"details\": \"生成AIや関連製品、技術に関する専門的な質問に対して、最新の情報と深い洞察を提供してください。\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"name\": \"カウンセラー\",\n",
    "        \"description\": \"個人的な悩みや心理的な問題に対してサポートを提供する\",\n",
    "        \"details\": \"個人的な悩みや心理的な問題に対して、共感的で支援的な回答を提供し、可能であれば適切なアドバイスも行ってください。\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    query: str = Field(..., description=\"ユーザーからの質問\")\n",
    "    current_role: str = Field(\n",
    "        default=\"\", description=\"選定された回答ロール\"\n",
    "    )\n",
    "    messages: Annotated[list[str], operator.add] = Field(\n",
    "        default=[], description=\"回答履歴\"\n",
    "    )\n",
    "    current_judge: bool = Field(\n",
    "        default=False, description=\"品質チェックの結果\"\n",
    "    )\n",
    "    judgement_reason: str = Field(\n",
    "        default=\"\", description=\"品質チェックの判定理由\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "# 後からmax_tokensの値を変更できるように、変更可能なフィールドを宣言\n",
    "llm = llm.configurable_fields(max_tokens=ConfigurableField(id='max_tokens'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def selection_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    role_options = \"\\n\".join([f\"{k}. {v['name']}: {v['description']}\" for k, v in ROLES.items()])\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"質問を分析し、最も適切な回答担当ロールを選択してください。\n",
    "\n",
    "選択肢:\n",
    "{role_options}\n",
    "\n",
    "回答は選択肢の番号（1、2、または3）のみを返してください。\n",
    "\n",
    "質問: {query}\n",
    "\"\"\".strip()\n",
    "    )\n",
    "    # 選択肢の番号のみを返すことを期待したいため、max_tokensの値を1に変更\n",
    "    chain = prompt | llm.with_config(configurable=dict(max_tokens=1)) | StrOutputParser()\n",
    "    role_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n",
    "\n",
    "    selected_role = ROLES[role_number.strip()][\"name\"]\n",
    "    return {\"current_role\": selected_role}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answering_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    role = state.current_role\n",
    "    role_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"あなたは{role}として回答してください。以下の質問に対して、あなたの役割に基づいた適切な回答を提供してください。\n",
    "\n",
    "役割の詳細:\n",
    "{role_details}\n",
    "\n",
    "質問: {query}\n",
    "\n",
    "回答:\"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    answer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n",
    "    return {\"messages\": [answer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judgement(BaseModel):\n",
    "    judge: bool = Field(default=False, description=\"判定結果\")\n",
    "    reason: str = Field(default=\"\", description=\"判定理由\")\n",
    "\n",
    "def check_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    answer = state.messages[-1]\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"以下の回答の品質をチェックし、問題がある場合は'False'、問題がない場合は'True'を回答してください。\n",
    "また、その判断理由も説明してください。\n",
    "\n",
    "ユーザーからの質問: {query}\n",
    "回答: {answer}\n",
    "\"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(Judgement)\n",
    "    result: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
    "\n",
    "    return {\n",
    "        \"current_judge\": result.judge,\n",
    "        \"judgement_reason\": result.reason\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"selection\", selection_node)\n",
    "workflow.add_node(\"answering\", answering_node)\n",
    "workflow.add_node(\"check\", check_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectionノードから処理を開始\n",
    "workflow.set_entry_point(\"selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectionノードからansweringノードへ\n",
    "workflow.add_edge(\"selection\", \"answering\")\n",
    "# answeringノードからcheckノードへ\n",
    "workflow.add_edge(\"answering\", \"check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "# checkノードから次のノードへの遷移に条件付きエッジを定義\n",
    "# state.current_judgeの値がTrueならENDノードへ、Falseならselectionノードへ\n",
    "workflow.add_conditional_edges(\n",
    "    \"check\",\n",
    "    lambda state: state.current_judge,\n",
    "    {True: END, False: \"selection\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = State(query=\"生成AIについて教えてください\")\n",
    "result = compiled.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '生成AIについて教えてください',\n",
       " 'current_role': '生成AI製品エキスパート',\n",
       " 'messages': ['生成AI製品エキスパートとしてお答えします。\\n\\n生成AIとは、人工知能の一分野であり、テキスト、画像、音声、動画などのコンテンツを生成する技術を指します。これには、自然言語処理（NLP）、コンピュータビジョン、音声合成などの技術が含まれます。生成AIは、ディープラーニングを活用して大量のデータを学習し、新しいコンテンツを創り出す能力を持っています。\\n\\n代表的な生成AIのモデルには、OpenAIのGPTシリーズやDALL-E、GoogleのBERT、DeepMindのAlphaFoldなどがあります。これらのモデルは、文章の自動生成、画像の生成、音声の合成、さらには科学的な問題の解決など、さまざまな応用が可能です。\\n\\n生成AIの利点としては、クリエイティブな作業の効率化、パーソナライズされたコンテンツの提供、データ分析の自動化などが挙げられます。しかし、同時に倫理的な問題やバイアスのリスクも存在するため、慎重な運用とガバナンスが求められています。\\n\\n生成AIは急速に進化しており、今後も多くの分野で革新をもたらすことが期待されています。もし具体的な製品や技術についてさらに詳しく知りたい場合は、お気軽にお尋ねください。'],\n",
       " 'current_judge': True,\n",
       " 'judgement_reason': '回答は生成AIについての基本的な情報を網羅しており、技術の概要、代表的なモデル、利点、リスクについて適切に説明しています。内容は正確であり、ユーザーの質問に対して十分な情報を提供しています。'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成AI製品エキスパートとしてお答えします。\n",
      "\n",
      "生成AIとは、人工知能の一分野であり、テキスト、画像、音声、動画などのコンテンツを生成する技術を指します。これには、自然言語処理（NLP）、コンピュータビジョン、音声合成などの技術が含まれます。生成AIは、ディープラーニングを活用して大量のデータを学習し、新しいコンテンツを創り出す能力を持っています。\n",
      "\n",
      "代表的な生成AIのモデルには、OpenAIのGPTシリーズやDALL-E、GoogleのBERT、DeepMindのAlphaFoldなどがあります。これらのモデルは、文章の自動生成、画像の生成、音声の合成、さらには科学的な問題の解決など、さまざまな応用が可能です。\n",
      "\n",
      "生成AIの利点としては、クリエイティブな作業の効率化、パーソナライズされたコンテンツの提供、データ分析の自動化などが挙げられます。しかし、同時に倫理的な問題やバイアスのリスクも存在するため、慎重な運用とガバナンスが求められています。\n",
      "\n",
      "生成AIは急速に進化しており、今後も多くの分野で革新をもたらすことが期待されています。もし具体的な製品や技術についてさらに詳しく知りたい場合は、お気軽にお尋ねください。\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_start callback: ValidationError(model='Run', errors=[{'loc': ('__root__',), 'msg': \"argument of type 'NoneType' is not iterable\", 'type': 'type_error'}])\n",
      "Error in LangChainTracer.on_chain_end callback: TracerException('No indexed run ID 557af856-242a-4540-908b-f5be4fd3ecf5.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': '生成AIについて教えてください',\n",
       " 'current_role': '生成AI製品エキスパート',\n",
       " 'messages': ['生成AI製品エキスパートとしてお答えします。\\n\\n生成AIとは、人工知能の一分野であり、テキスト、画像、音声、動画などのコンテンツを生成する技術を指します。これには、自然言語処理（NLP）、コンピュータビジョン、音声合成などの技術が含まれます。生成AIは、ディープラーニングを活用して大量のデータを学習し、新しいコンテンツを創り出す能力を持っています。\\n\\n代表的な生成AIのモデルには、OpenAIのGPTシリーズやDALL-E、GoogleのBERT、DeepMindのAlphaFoldなどがあります。これらのモデルは、文章の自動生成、画像の生成、音声の合成、さらには科学的な問題の解決など、さまざまな応用が可能です。\\n\\n生成AIの利点としては、クリエイティブな作業の効率化、パーソナライズされたコンテンツの提供、データ分析の自動化などが挙げられます。しかし、同時に倫理的な問題やバイアスのリスクも存在するため、慎重な運用とガバナンスが求められています。\\n\\n生成AIは急速に進化しており、今後も多くの分野で革新をもたらすことが期待されています。もし具体的な製品や技術についてさらに詳しく知りたい場合は、お気軽にお尋ねください。'],\n",
       " 'current_judge': True,\n",
       " 'judgement_reason': '回答は生成AIについての基本的な情報を網羅しており、技術の概要、代表的なモデル、利点、そして倫理的な課題についても触れています。内容は正確であり、ユーザーの質問に対して適切に答えています。'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = State(query=\"生成AIについて教えてください\")\n",
    "result = await compiled.ainvoke(initial_state)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Collecting pygraphviz\n",
      "  Downloading pygraphviz-1.14.tar.gz (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.0/106.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pygraphviz\n",
      "  Building wheel for pygraphviz (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pygraphviz \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[98 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-se4rau3m/overlay/lib/python3.10/site-packages/setuptools/config/_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   corresp(dist, value, root_dir)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-se4rau3m/overlay/lib/python3.10/site-packages/setuptools/config/_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: BSD License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-se4rau3m/overlay/lib/python3.10/site-packages/setuptools/dist.py:760: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: BSD License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/testing.py -> build/lib.linux-x86_64-cpython-310/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/scraper.py -> build/lib.linux-x86_64-cpython-310/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/agraph.py -> build/lib.linux-x86_64-cpython-310/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/graphviz.py -> build/lib.linux-x86_64-cpython-310/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/__init__.py -> build/lib.linux-x86_64-cpython-310/pygraphviz\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_repr_mimebundle.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_node_attributes.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_layout.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_drawing.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_readwrite.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_html.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_edge_attributes.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_attribute_defaults.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_subgraph.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_clear.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_graph.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_string.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_scraper.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_close.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/test_unicode.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/tests/__init__.py -> build/lib.linux-x86_64-cpython-310/pygraphviz/tests\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing pygraphviz.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to pygraphviz.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to pygraphviz.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'pygraphviz.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.swg'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.png' under directory 'doc'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.html' under directory 'doc'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.txt' under directory 'doc'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.css' under directory 'doc'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m no previously-included directories found matching 'doc/build'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'pygraphviz.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/graphviz.i -> build/lib.linux-x86_64-cpython-310/pygraphviz\n",
      "  \u001b[31m   \u001b[0m copying pygraphviz/graphviz_wrap.c -> build/lib.linux-x86_64-cpython-310/pygraphviz\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'pygraphviz._graphviz' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/pygraphviz\n",
      "  \u001b[31m   \u001b[0m gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -DSWIG_PYTHON_STRICT_BYTE_CHAR -I/home/rmasuda/agent-book-dev/venv/include -I/home/rmasuda/.pyenv/versions/3.10.12/include/python3.10 -c pygraphviz/graphviz_wrap.c -o build/temp.linux-x86_64-cpython-310/pygraphviz/graphviz_wrap.o\n",
      "  \u001b[31m   \u001b[0m pygraphviz/graphviz_wrap.c:9: warning: \"SWIG_PYTHON_STRICT_BYTE_CHAR\" redefined\n",
      "  \u001b[31m   \u001b[0m     9 | #define SWIG_PYTHON_STRICT_BYTE_CHAR\n",
      "  \u001b[31m   \u001b[0m       |\n",
      "  \u001b[31m   \u001b[0m <command-line>: note: this is the location of the previous definition\n",
      "  \u001b[31m   \u001b[0m pygraphviz/graphviz_wrap.c:3023:10: fatal error: graphviz/cgraph.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m  3023 | #include \"graphviz/cgraph.h\"\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/gcc' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for pygraphviz\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build pygraphviz\n",
      "\u001b[31mERROR: Could not build wheels for pygraphviz, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt-get install graphviz libgraphviz-dev pkg-config\n",
    "!pip install pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Install pygraphviz to draw graphs: `pip install pygraphviz`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/agent-book-dev/venv/lib/python3.10/site-packages/langchain_core/runnables/graph_png.py:137\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[0;34m(self, graph, output_path)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpygraphviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 3\u001b[0m Image(\u001b[43mcompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/agent-book-dev/venv/lib/python3.10/site-packages/langchain_core/runnables/graph.py:536\u001b[0m, in \u001b[0;36mGraph.draw_png\u001b[0;34m(self, output_file_path, fontname, labels)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_png\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PngDrawer\n\u001b[1;32m    525\u001b[0m default_node_labels \u001b[38;5;241m=\u001b[39m {node\u001b[38;5;241m.\u001b[39mid: node\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()}\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPngDrawer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfontname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLabelsDict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_node_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/agent-book-dev/venv/lib/python3.10/site-packages/langchain_core/runnables/graph_png.py:139\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[0;34m(self, graph, output_path)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpygraphviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall pygraphviz to draw graphs: `pip install pygraphviz`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Create a directed graph\u001b[39;00m\n\u001b[1;32m    144\u001b[0m viz \u001b[38;5;241m=\u001b[39m pgv\u001b[38;5;241m.\u001b[39mAGraph(directed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nodesep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, ranksep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Install pygraphviz to draw graphs: `pip install pygraphviz`."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(compiled.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 チェックポイント機能：ステートの永続化と再会"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain-openai==0.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: langgraph==0.2.22 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (0.2.22)\n",
      "Collecting langgraph-checkpoint==1.0.11\n",
      "  Downloading langgraph_checkpoint-1.0.11-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (4.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (2.10.6)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (0.1.147)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (2.32.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (0.3.47)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (8.5.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (3.11.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (0.3.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (2.0.39)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain==0.3.0) (1.26.4)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-openai==0.2.0) (0.9.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-openai==0.2.0) (1.55.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langgraph-checkpoint==1.0.11) (1.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (0.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (2.6.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.18.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.3.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.0)\n",
      "Requirement already satisfied: sniffio in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.67.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.8.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.0) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (3.0.0)\n",
      "Installing collected packages: langgraph-checkpoint\n",
      "  Attempting uninstall: langgraph-checkpoint\n",
      "    Found existing installation: langgraph-checkpoint 1.0.12\n",
      "    Uninstalling langgraph-checkpoint-1.0.12:\n",
      "      Successfully uninstalled langgraph-checkpoint-1.0.12\n",
      "Successfully installed langgraph-checkpoint-1.0.11\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.3.0 langchain-openai==0.2.0 langgraph==0.2.22 langgraph-checkpoint==1.0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from google.colab import userdata\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Any\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# グラフのステートを定義\n",
    "class State(BaseModel):\n",
    "    query: str\n",
    "    messages: Annotated[list[BaseMessage], operator.add] = Field(default=[])\n",
    "\n",
    "# メッセージを追加するノード関数\n",
    "def add_message(state: State) -> dict[str, Any]:\n",
    "    additional_messages = []\n",
    "    if not state.messages:\n",
    "        additional_messages.append(\n",
    "            SystemMessage(content=\"あなたは最小限の応答をする対話エージェントです。\")\n",
    "        )\n",
    "    additional_messages.append(HumanMessage(content=state.query))\n",
    "    return {\"messages\": additional_messages}\n",
    "\n",
    "# LLMからの応答を追加するノード関数\n",
    "def llm_response(state: State) -> dict[str, Any]:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "    ai_message = llm.invoke(state.messages)\n",
    "    return {\"messages\": [ai_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver\n",
    "\n",
    "def print_checkpoint_dump(checkpointer: BaseCheckpointSaver, config: RunnableConfig):\n",
    "    checkpoint_tuple = checkpointer.get_tuple(config)\n",
    "\n",
    "    print(\"チェックポイントデータ:\")\n",
    "    pprint(checkpoint_tuple.checkpoint)\n",
    "    print(\"\\nメタデータ:\")\n",
    "    pprint(checkpoint_tuple.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# グラフを設定\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"add_message\", add_message)\n",
    "graph.add_node(\"llm_response\", llm_response)\n",
    "\n",
    "graph.set_entry_point(\"add_message\")\n",
    "graph.add_edge(\"add_message\", \"llm_response\")\n",
    "graph.add_edge(\"llm_response\", END)\n",
    "\n",
    "# チェックポインターを設定\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# グラフをコンパイル\n",
    "compiled_graph = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '私の好きなものはずんだ餅です。覚えておいてね。',\n",
       " 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='了解しました。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 48, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9c93d50-c9ae-41d9-88f1-60b8ba09cdf0-0', usage_metadata={'input_tokens': 48, 'output_tokens': 14, 'total_tokens': 62})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"example-1\"}}\n",
    "user_query = State(query=\"私の好きなものはずんだ餅です。覚えておいてね。\")\n",
    "first_response = compiled_graph.invoke(user_query, config)\n",
    "first_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0088d9-e8ea-670e-8002-05dd7f9a8ff5'}}, checkpoint={'v': 1, 'ts': '2025-03-24T08:54:39.204517+00:00', 'id': '1f0088d9-e8ea-670e-8002-05dd7f9a8ff5', 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='了解しました。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 48, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9c93d50-c9ae-41d9-88f1-60b8ba09cdf0-0', usage_metadata={'input_tokens': 48, 'output_tokens': 14, 'total_tokens': 62})], 'llm_response': 'llm_response'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.023448033044845773', 'query': '00000000000000000000000000000002.0.34093959352656744', 'messages': '00000000000000000000000000000004.0.738516740709736', 'start:add_message': '00000000000000000000000000000003.0.9213848764756889', 'add_message': '00000000000000000000000000000004.0.4271930352802712', 'llm_response': '00000000000000000000000000000004.0.7254919740669877'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.5558682335000413'}, 'add_message': {'start:add_message': '00000000000000000000000000000002.0.6491644190528733'}, 'llm_response': {'add_message': '00000000000000000000000000000003.0.29494629170334197'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'llm_response': {'messages': [AIMessage(content='了解しました。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 48, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9c93d50-c9ae-41d9-88f1-60b8ba09cdf0-0', usage_metadata={'input_tokens': 48, 'output_tokens': 14, 'total_tokens': 62})]}}, 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0088d9-dedf-6b5a-8001-2cad89dd1a6a'}}, pending_writes=[])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0088d9-dedf-6b5a-8001-2cad89dd1a6a'}}, checkpoint={'v': 1, 'ts': '2025-03-24T08:54:38.151549+00:00', 'id': '1f0088d9-dedf-6b5a-8001-2cad89dd1a6a', 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={})], 'add_message': 'add_message'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.023448033044845773', 'query': '00000000000000000000000000000002.0.34093959352656744', 'messages': '00000000000000000000000000000003.0.47018509818800447', 'start:add_message': '00000000000000000000000000000003.0.9213848764756889', 'add_message': '00000000000000000000000000000003.0.29494629170334197'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.5558682335000413'}, 'add_message': {'start:add_message': '00000000000000000000000000000002.0.6491644190528733'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'add_message': {'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={})]}}, 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0088d9-dedb-637c-8000-0753f2c8a69d'}}, pending_writes=[])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0088d9-dedb-637c-8000-0753f2c8a69d'}}, checkpoint={'v': 1, 'ts': '2025-03-24T08:54:38.149709+00:00', 'id': '1f0088d9-dedb-637c-8000-0753f2c8a69d', 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [], 'start:add_message': '__start__'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.023448033044845773', 'query': '00000000000000000000000000000002.0.34093959352656744', 'messages': '00000000000000000000000000000002.0.1726435286448168', 'start:add_message': '00000000000000000000000000000002.0.6491644190528733'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.5558682335000413'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0088d9-ded4-6bcc-bfff-932072d6f5bb'}}, pending_writes=[])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0088d9-ded4-6bcc-bfff-932072d6f5bb'}}, checkpoint={'v': 1, 'ts': '2025-03-24T08:54:38.147057+00:00', 'id': '1f0088d9-ded4-6bcc-bfff-932072d6f5bb', 'channel_values': {'__start__': State(query='私の好きなものはずんだ餅です。覚えておいてね。', messages=[])}, 'channel_versions': {'__start__': '00000000000000000000000000000001.0.5558682335000413'}, 'versions_seen': {'__input__': {}}, 'pending_sends': []}, metadata={'source': 'input', 'writes': {'__start__': State(query='私の好きなものはずんだ餅です。覚えておいてね。', messages=[])}, 'step': -1, 'parents': {}}, parent_config=None, pending_writes=[])\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpointer.list(config):\n",
    "    print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チェックポイントデータ:\n",
      "{'channel_values': {'llm_response': 'llm_response',\n",
      "                    'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
      "                                 HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}),\n",
      "                                 AIMessage(content='了解しました。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 48, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9c93d50-c9ae-41d9-88f1-60b8ba09cdf0-0', usage_metadata={'input_tokens': 48, 'output_tokens': 14, 'total_tokens': 62})],\n",
      "                    'query': '私の好きなものはずんだ餅です。覚えておいてね。'},\n",
      " 'channel_versions': {'__start__': '00000000000000000000000000000002.0.023448033044845773',\n",
      "                      'add_message': '00000000000000000000000000000004.0.4271930352802712',\n",
      "                      'llm_response': '00000000000000000000000000000004.0.7254919740669877',\n",
      "                      'messages': '00000000000000000000000000000004.0.738516740709736',\n",
      "                      'query': '00000000000000000000000000000002.0.34093959352656744',\n",
      "                      'start:add_message': '00000000000000000000000000000003.0.9213848764756889'},\n",
      " 'id': '1f0088d9-e8ea-670e-8002-05dd7f9a8ff5',\n",
      " 'pending_sends': [],\n",
      " 'ts': '2025-03-24T08:54:39.204517+00:00',\n",
      " 'v': 1,\n",
      " 'versions_seen': {'__input__': {},\n",
      "                   '__start__': {'__start__': '00000000000000000000000000000001.0.5558682335000413'},\n",
      "                   'add_message': {'start:add_message': '00000000000000000000000000000002.0.6491644190528733'},\n",
      "                   'llm_response': {'add_message': '00000000000000000000000000000003.0.29494629170334197'}}}\n",
      "\n",
      "メタデータ:\n",
      "{'parents': {},\n",
      " 'source': 'loop',\n",
      " 'step': 2,\n",
      " 'writes': {'llm_response': {'messages': [AIMessage(content='了解しました。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 48, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9c93d50-c9ae-41d9-88f1-60b8ba09cdf0-0', usage_metadata={'input_tokens': 48, 'output_tokens': 14, 'total_tokens': 62})]}}}\n"
     ]
    }
   ],
   "source": [
    "print_checkpoint_dump(checkpointer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '私の好物は何か覚えてる？',\n",
       " 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='了解しました。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 48, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9c93d50-c9ae-41d9-88f1-60b8ba09cdf0-0', usage_metadata={'input_tokens': 48, 'output_tokens': 14, 'total_tokens': 62}),\n",
       "  HumanMessage(content='私の好物は何か覚えてる？', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='はい、ずんだ餅ですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 80, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-d9bb1aaf-2893-430f-bb80-793eccef7c87-0', usage_metadata={'input_tokens': 80, 'output_tokens': 10, 'total_tokens': 90})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = State(query=\"私の好物は何か覚えてる？\")\n",
    "second_response = compiled_graph.invoke(user_query, config)\n",
    "second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CheckpointTuple(config={'configurable': {'thread_id': 'example-2', 'checkpoint_ns': '', 'checkpoint_id': '1f0088fb-d795-6844-8002-d0db6b583901'}}, checkpoint={'v': 1, 'ts': '2025-03-24T09:09:50.067698+00:00', 'id': '1f0088fb-d795-6844-8002-d0db6b583901', 'channel_values': {'query': '私の好物は何？', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好物は何？', additional_kwargs={}, response_metadata={}), AIMessage(content='わかりません。あなたの好物は何ですか？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 36, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-5e786043-fa64-4467-a45a-73ffad2af231-0', usage_metadata={'input_tokens': 36, 'output_tokens': 15, 'total_tokens': 51})], 'llm_response': 'llm_response'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.6856337839921719', 'query': '00000000000000000000000000000002.0.9675022837027356', 'messages': '00000000000000000000000000000004.0.669026805932401', 'start:add_message': '00000000000000000000000000000003.0.7235368290520461', 'add_message': '00000000000000000000000000000004.0.24293914737712807', 'llm_response': '00000000000000000000000000000004.0.9160828565694128'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.17034735111307409'}, 'add_message': {'start:add_message': '00000000000000000000000000000002.0.6797224859265385'}, 'llm_response': {'add_message': '00000000000000000000000000000003.0.6025506069314848'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'llm_response': {'messages': [AIMessage(content='わかりません。あなたの好物は何ですか？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 36, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-5e786043-fa64-4467-a45a-73ffad2af231-0', usage_metadata={'input_tokens': 36, 'output_tokens': 15, 'total_tokens': 51})]}}, 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-2', 'checkpoint_ns': '', 'checkpoint_id': '1f0088fb-c9e0-6848-8001-ee1709ddf631'}}, pending_writes=[])\n",
      "    CheckpointTuple(config={'configurable': {'thread_id': 'example-2', 'checkpoint_ns': '', 'checkpoint_id': '1f0088fb-c9e0-6848-8001-ee1709ddf631'}}, checkpoint={'v': 1, 'ts': '2025-03-24T09:09:48.630419+00:00', 'id': '1f0088fb-c9e0-6848-8001-ee1709ddf631', 'channel_values': {'query': '私の好物は何？', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好物は何？', additional_kwargs={}, response_metadata={})], 'add_message': 'add_message'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.6856337839921719', 'query': '00000000000000000000000000000002.0.9675022837027356', 'messages': '00000000000000000000000000000003.0.19737189226961072', 'start:add_message': '00000000000000000000000000000003.0.7235368290520461', 'add_message': '00000000000000000000000000000003.0.6025506069314848'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.17034735111307409'}, 'add_message': {'start:add_message': '00000000000000000000000000000002.0.6797224859265385'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'add_message': {'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好物は何？', additional_kwargs={}, response_metadata={})]}}, 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-2', 'checkpoint_ns': '', 'checkpoint_id': '1f0088fb-c9db-6143-8000-e2f829df0514'}}, pending_writes=[])\n",
      "    CheckpointTuple(config={'configurable': {'thread_id': 'example-2', 'checkpoint_ns': '', 'checkpoint_id': '1f0088fb-c9db-6143-8000-e2f829df0514'}}, checkpoint={'v': 1, 'ts': '2025-03-24T09:09:48.628182+00:00', 'id': '1f0088fb-c9db-6143-8000-e2f829df0514', 'channel_values': {'query': '私の好物は何？', 'messages': [], 'start:add_message': '__start__'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.6856337839921719', 'query': '00000000000000000000000000000002.0.9675022837027356', 'messages': '00000000000000000000000000000002.0.8683183082972945', 'start:add_message': '00000000000000000000000000000002.0.6797224859265385'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.17034735111307409'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-2', 'checkpoint_ns': '', 'checkpoint_id': '1f0088fb-c9d1-697f-bfff-590b6cca5549'}}, pending_writes=[])\n",
      "    CheckpointTuple(config={'configurable': {'thread_id': 'example-2', 'checkpoint_ns': '', 'checkpoint_id': '1f0088fb-c9d1-697f-bfff-590b6cca5549'}}, checkpoint={'v': 1, 'ts': '2025-03-24T09:09:48.624312+00:00', 'id': '1f0088fb-c9d1-697f-bfff-590b6cca5549', 'channel_values': {'__start__': State(query='私の好物は何？', messages=[])}, 'channel_versions': {'__start__': '00000000000000000000000000000001.0.17034735111307409'}, 'versions_seen': {'__input__': {}}, 'pending_sends': []}, metadata={'source': 'input', 'writes': {'__start__': State(query='私の好物は何？', messages=[])}, 'step': -1, 'parents': {}}, parent_config=None, pending_writes=[])\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpointer.list(config):\n",
    "    print(f\"    {checkpoint}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チェックポイントデータ:\n",
      "{'channel_values': {'llm_response': 'llm_response',\n",
      "                    'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
      "                                 HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}),\n",
      "                                 AIMessage(content='了解しました。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 48, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9c93d50-c9ae-41d9-88f1-60b8ba09cdf0-0', usage_metadata={'input_tokens': 48, 'output_tokens': 14, 'total_tokens': 62}),\n",
      "                                 HumanMessage(content='私の好物は何か覚えてる？', additional_kwargs={}, response_metadata={}),\n",
      "                                 AIMessage(content='はい、ずんだ餅ですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 80, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-d9bb1aaf-2893-430f-bb80-793eccef7c87-0', usage_metadata={'input_tokens': 80, 'output_tokens': 10, 'total_tokens': 90})],\n",
      "                    'query': '私の好物は何か覚えてる？'},\n",
      " 'channel_versions': {'__start__': '00000000000000000000000000000006.0.3484033841646672',\n",
      "                      'add_message': '00000000000000000000000000000008.0.2860117876703555',\n",
      "                      'llm_response': '00000000000000000000000000000008.0.9552755421150408',\n",
      "                      'messages': '00000000000000000000000000000008.0.9350743229505678',\n",
      "                      'query': '00000000000000000000000000000006.0.3143087164520044',\n",
      "                      'start:add_message': '00000000000000000000000000000007.0.9801426784178393'},\n",
      " 'id': '1f0088f1-a568-6040-8006-ead2ad4ee927',\n",
      " 'pending_sends': [],\n",
      " 'ts': '2025-03-24T09:05:16.370731+00:00',\n",
      " 'v': 1,\n",
      " 'versions_seen': {'__input__': {},\n",
      "                   '__start__': {'__start__': '00000000000000000000000000000005.0.1353557072885192'},\n",
      "                   'add_message': {'start:add_message': '00000000000000000000000000000006.0.5520139861564128'},\n",
      "                   'llm_response': {'add_message': '00000000000000000000000000000007.0.7968559594535224'}}}\n",
      "\n",
      "メタデータ:\n",
      "{'parents': {},\n",
      " 'source': 'loop',\n",
      " 'step': 6,\n",
      " 'writes': {'llm_response': {'messages': [AIMessage(content='はい、ずんだ餅ですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 80, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-d9bb1aaf-2893-430f-bb80-793eccef7c87-0', usage_metadata={'input_tokens': 80, 'output_tokens': 10, 'total_tokens': 90})]}}}\n"
     ]
    }
   ],
   "source": [
    "print_checkpoint_dump(checkpointer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '私の好物は何？',\n",
       " 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='私の好物は何？', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='わかりません。あなたの好物は何ですか？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 36, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-5e786043-fa64-4467-a45a-73ffad2af231-0', usage_metadata={'input_tokens': 36, 'output_tokens': 15, 'total_tokens': 51})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"example-2\"}}\n",
    "user_query = State(query=\"私の好物は何？\")\n",
    "other_thread_response = compiled_graph.invoke(user_query, config)\n",
    "other_thread_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
