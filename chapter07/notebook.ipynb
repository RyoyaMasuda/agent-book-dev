{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LangSmith を使った RAG アプリケーションの評価\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:34.489407Z",
     "iopub.status.busy": "2024-06-28T02:32:34.488775Z",
     "iopub.status.idle": "2024-06-28T02:32:34.491583Z",
     "shell.execute_reply": "2024-06-28T02:32:34.491086Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# from google.colab import userdata\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Ragas による合成テストデータの生成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パッケージのインストール\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-core==0.2.30\n",
      "  Downloading langchain_core-0.2.30-py3-none-any.whl (384 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.8/384.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai==0.1.21\n",
      "  Downloading langchain_openai-0.1.21-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-community==0.2.12\n",
      "  Using cached langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
      "Requirement already satisfied: GitPython==3.1.43 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (3.1.43)\n",
      "Collecting langchain-chroma==0.1.2\n",
      "  Using cached langchain_chroma-0.1.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting chromadb==0.5.3\n",
      "  Using cached chromadb-0.5.3-py3-none-any.whl (559 kB)\n",
      "Collecting ragas==0.1.14\n",
      "  Using cached ragas-0.1.14-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.2.30) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.2.30) (4.12.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.2.30) (8.5.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.2.30) (24.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.2.30) (0.1.147)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.2.30) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.2.30) (6.0.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-openai==0.1.21) (0.9.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-openai==0.1.21) (1.55.3)\n",
      "Collecting langchain<0.3.0,>=0.2.13\n",
      "  Downloading langchain-0.2.17-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: SQLAlchemy<3,>=1.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.2.12) (2.0.39)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.2.12) (1.26.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.2.12) (0.6.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.2.12) (2.32.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.2.12) (3.11.13)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from GitPython==3.1.43) (4.0.12)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-chroma==0.1.2) (0.115.11)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (3.10.15)\n",
      "Collecting chroma-hnswlib==0.7.3\n",
      "  Using cached chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "Requirement already satisfied: importlib-resources in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (6.5.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (3.20.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (0.20.3)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (1.31.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (4.3.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (0.34.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (7.7.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (1.71.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (32.0.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (1.31.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (5.1.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (4.67.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (1.31.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (0.15.2)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb==0.5.3) (1.2.2.post1)\n",
      "Collecting appdirs\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pysbd>=0.3.4\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.12) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.12) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.12) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.12) (0.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.12) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.12) (25.3.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.12) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.12) (1.18.3)\n",
      "Requirement already satisfied: pyproject_hooks in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb==0.5.3) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb==0.5.3) (2.2.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12) (3.26.1)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain-chroma==0.1.2) (0.46.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython==3.1.43) (5.0.2)\n",
      "Requirement already satisfied: idna in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb==0.5.3) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb==0.5.3) (1.0.7)\n",
      "Requirement already satisfied: anyio in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb==0.5.3) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb==0.5.3) (2025.1.31)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.5.3) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.30) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.5.3) (2.9.0.post0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.5.3) (2.0.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.5.3) (1.8.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.5.3) (2.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.5.3) (1.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.5.3) (2.38.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.5.3) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.5.3) (0.9)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Collecting langchain<0.3.0,>=0.2.13\n",
      "  Downloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading langchain-0.2.15-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading langchain-0.2.14-py3-none-any.whl (997 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading langchain-0.2.13-py3-none-any.whl (997 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core==0.2.30) (1.0.0)\n",
      "Requirement already satisfied: protobuf in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.3) (5.29.3)\n",
      "Requirement already satisfied: flatbuffers in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.3) (25.2.10)\n",
      "Requirement already satisfied: coloredlogs in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.3) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.3) (1.13.3)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.1.21) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.1.21) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.1.21) (1.9.0)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.3) (8.6.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.3) (1.2.18)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.3) (1.69.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.3) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.3) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.3) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.3) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.3) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.3) (0.52b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.3) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.3) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.5.3) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.5.3) (2.2.1)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core==0.2.30) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core==0.2.30) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.2.12) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.2.12) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.21) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb==0.5.3) (0.29.3)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.5.3) (13.9.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.5.3) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.5.3) (1.5.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.3) (0.21.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.3) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.3) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.3) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.3) (15.0.1)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Requirement already satisfied: pandas in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from datasets->ragas==0.1.14) (2.2.3)\n",
      "Requirement already satisfied: filelock in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from datasets->ragas==0.1.14) (3.17.0)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess<0.70.17\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Collecting fsspec[http]<=2024.12.0,>=2023.1.0\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb==0.5.3) (1.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.3) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.3) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.3) (5.5.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.3) (3.21.0)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.3) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.3) (2.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.3) (10.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pandas->datasets->ragas==0.1.14) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pandas->datasets->ragas==0.1.14) (2025.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.3) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.5.3) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.3) (0.6.1)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'langchain-openai' candidate (version 0.1.21 at https://files.pythonhosted.org/packages/e5/0c/7c752ba4a6fa8719f9f8cf8e22f0e2c8bbcdac5f8a580dd12a1496cd5031/langchain_openai-0.1.21-py3-none-any.whl (from https://pypi.org/simple/langchain-openai/) (requires-python:<4.0,>=3.8.1))\n",
      "Reason for being yanked: Regression. AzureChatOpenAI json-mode broken. Fixed in 0.1.22.\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: appdirs, xxhash, pysbd, pyarrow, fsspec, dill, chroma-hnswlib, multiprocess, langchain-core, langchain-text-splitters, langchain-openai, datasets, langchain, langchain-community, chromadb, ragas, langchain-chroma\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "  Attempting uninstall: chroma-hnswlib\n",
      "    Found existing installation: chroma-hnswlib 0.7.6\n",
      "    Uninstalling chroma-hnswlib-0.7.6:\n",
      "      Successfully uninstalled chroma-hnswlib-0.7.6\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.45\n",
      "    Uninstalling langchain-core-0.3.45:\n",
      "      Successfully uninstalled langchain-core-0.3.45\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.0\n",
      "    Uninstalling langchain-text-splitters-0.3.0:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.0\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.2.0\n",
      "    Uninstalling langchain-openai-0.2.0:\n",
      "      Successfully uninstalled langchain-openai-0.2.0\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.0\n",
      "    Uninstalling langchain-0.3.0:\n",
      "      Successfully uninstalled langchain-0.3.0\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.0\n",
      "    Uninstalling langchain-community-0.3.0:\n",
      "      Successfully uninstalled langchain-community-0.3.0\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 0.5.23\n",
      "    Uninstalling chromadb-0.5.23:\n",
      "      Successfully uninstalled chromadb-0.5.23\n",
      "  Attempting uninstall: langchain-chroma\n",
      "    Found existing installation: langchain-chroma 0.1.4\n",
      "    Uninstalling langchain-chroma-0.1.4:\n",
      "      Successfully uninstalled langchain-chroma-0.1.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-experimental 0.3.4 requires langchain-community<0.4.0,>=0.3.0, but you have langchain-community 0.2.12 which is incompatible.\n",
      "langchain-experimental 0.3.4 requires langchain-core<0.4.0,>=0.3.28, but you have langchain-core 0.2.30 which is incompatible.\n",
      "langchain-cohere 0.3.0 requires langchain-core<0.4,>=0.3.0, but you have langchain-core 0.2.30 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed appdirs-1.4.4 chroma-hnswlib-0.7.3 chromadb-0.5.3 datasets-3.4.1 dill-0.3.8 fsspec-2024.12.0 langchain-0.2.13 langchain-chroma-0.1.2 langchain-community-0.2.12 langchain-core-0.2.30 langchain-openai-0.1.21 langchain-text-splitters-0.2.2 multiprocess-0.70.16 pyarrow-19.0.1 pysbd-0.3.4 ragas-0.1.14 xxhash-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-core==0.2.30 langchain-openai==0.1.21 \\\n",
    "    langchain-community==0.2.12 GitPython==3.1.43 \\\n",
    "    langchain-chroma==0.1.2 chromadb==0.5.3 \\\n",
    "    ragas==0.1.14 nest-asyncio==1.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検索対象のドキュメントのロード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    return file_path.endswith(\".mdx\")\n",
    "\n",
    "\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
    "    repo_path=\"./langchain\",\n",
    "    branch=\"master\",\n",
    "    file_filter=file_filter,\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragas による合成テストデータ生成の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    document.metadata[\"filename\"] = document.metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【注意】既知のエラーについて\n",
    "\n",
    "以下のコードで gpt-4o を使用すると OpenAI API の Usage tier 次第で RateLimitError が発生することが報告されています。\n",
    "\n",
    "OpenAI API の Usage tier については公式ドキュメントの以下のページを参照してください。\n",
    "\n",
    "https://platform.openai.com/docs/guides/rate-limits/usage-tiers\n",
    "\n",
    "このエラーが発生した場合は、以下のどちらかの対応を実施してください。\n",
    "\n",
    "1. 同じ Tier でも gpt-4o よりレートリミットの高い gpt-4o-mini を使用する\n",
    "   - この場合、生成される合成テストデータの品質は低くなることが想定されます\n",
    "2. 課金などにより Tier を上げる\n",
    "   - Tier 2 で RateLimitError が発生しないことを確認済みです (2024 年 10 月 31 日時点)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating: 100%|██████████| 4/4 [00:12<00:00,  3.08s/it]           \n"
     ]
    }
   ],
   "source": [
    "# testset.csvがある場合はコメントアウト（料金結構かかるから）\n",
    "\n",
    "import nest_asyncio\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    # generator_llm=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    generator_llm=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    # critic_llm=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    critic_llm=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    embeddings=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents,\n",
    "    test_size=4,\n",
    "    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What models does GigaChat LLM provide?</td>\n",
       "      <td>[# Salute Devices\\n\\nSalute Devices provides G...</td>\n",
       "      <td>GigaChat LLM provides models for chat and embe...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the purpose of the chat model in the C...</td>\n",
       "      <td>[# Cohere\\n\\n&gt;[Cohere](https://cohere.ai/about...</td>\n",
       "      <td>The purpose of the chat model in the Cohere in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What services does Naver offer with AI and cloud?</td>\n",
       "      <td>[# NAVER\\n\\nAll functionality related to `Nave...</td>\n",
       "      <td>Naver offers a comprehensive suite of cloud se...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's a Python snippet for using HyperCLOVA X...</td>\n",
       "      <td>[# NAVER\\n\\nAll functionality related to `Nave...</td>\n",
       "      <td>A Python snippet for using HyperCLOVA X in Nav...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0             What models does GigaChat LLM provide?   \n",
       "1  What is the purpose of the chat model in the C...   \n",
       "2  What services does Naver offer with AI and cloud?   \n",
       "3  What's a Python snippet for using HyperCLOVA X...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [# Salute Devices\\n\\nSalute Devices provides G...   \n",
       "1  [# Cohere\\n\\n>[Cohere](https://cohere.ai/about...   \n",
       "2  [# NAVER\\n\\nAll functionality related to `Nave...   \n",
       "3  [# NAVER\\n\\nAll functionality related to `Nave...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  GigaChat LLM provides models for chat and embe...         simple   \n",
       "1  The purpose of the chat model in the Cohere in...         simple   \n",
       "2  Naver offers a comprehensive suite of cloud se...      reasoning   \n",
       "3  A Python snippet for using HyperCLOVA X in Nav...  multi_context   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'docs/docs/integrations/providers/...          True  \n",
       "1  [{'source': 'docs/docs/integrations/providers/...          True  \n",
       "2  [{'source': 'docs/docs/integrations/providers/...          True  \n",
       "3  [{'source': 'docs/docs/integrations/providers/...          True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(testset.to_pandas())\n",
    "\n",
    "# 一回保存\n",
    "testset.to_pandas().to_csv('testset.cdv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith の Dataset の作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "dataset_name = \"agent-book\"\n",
    "\n",
    "client = Client()\n",
    "\n",
    "if client.has_dataset(dataset_name=dataset_name):\n",
    "    client.delete_dataset(dataset_name=dataset_name)\n",
    "\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合成テストデータの保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "metadatas = []\n",
    "\n",
    "for testset_record in testset.test_data:\n",
    "    inputs.append(\n",
    "        {\n",
    "            \"question\": testset_record.question,\n",
    "        }\n",
    "    )\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"contexts\": testset_record.contexts,\n",
    "            \"ground_truth\": testset_record.ground_truth,\n",
    "        }\n",
    "    )\n",
    "    metadatas.append(\n",
    "        {\n",
    "            \"source\": testset_record.metadata[0][\"source\"],\n",
    "            \"evolution_type\": testset_record.evolution_type,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_examples(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    metadata=metadatas,\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. LangSmith と Ragas を使ったオフライン評価の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カスタム Evaluator の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langsmith.schemas import Example, Run\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics.base import Metric, MetricWithEmbeddings, MetricWithLLM\n",
    "\n",
    "\n",
    "class RagasMetricEvaluator:\n",
    "    def __init__(self, metric: Metric, llm: BaseChatModel, embeddings: Embeddings):\n",
    "        self.metric = metric\n",
    "\n",
    "        # LLMとEmbeddingsをMetricに設定\n",
    "        if isinstance(self.metric, MetricWithLLM):\n",
    "            self.metric.llm = LangchainLLMWrapper(llm)\n",
    "        if isinstance(self.metric, MetricWithEmbeddings):\n",
    "            self.metric.embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "    def evaluate(self, run: Run, example: Example) -> dict[str, Any]:\n",
    "        context_strs = [doc.page_content for doc in run.outputs[\"contexts\"]]\n",
    "\n",
    "        # Ragasの評価メトリクスのscoreメソッドでスコアを算出\n",
    "        score = self.metric.score(\n",
    "            {\n",
    "                \"question\": example.inputs[\"question\"],\n",
    "                \"answer\": run.outputs[\"answer\"],\n",
    "                \"contexts\": context_strs,\n",
    "                \"ground_truth\": example.outputs[\"ground_truth\"],\n",
    "            },\n",
    "        )\n",
    "        return {\"key\": self.metric.name, \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.metrics import answer_relevancy, context_precision\n",
    "\n",
    "metrics = [context_precision, answer_relevancy]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "evaluators = [\n",
    "    RagasMetricEvaluator(metric, llm, embeddings).evaluate\n",
    "    for metric in metrics\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論の関数の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "\n",
    "文脈: \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "質問: {question}\n",
    "''')\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": retriever,\n",
    "    }\n",
    ").assign(answer=prompt | model | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs: dict[str, Any]) -> dict[str, Any]:\n",
    "    question = inputs[\"question\"]\n",
    "    output = chain.invoke(question)\n",
    "    return {\n",
    "        \"contexts\": output[\"context\"],\n",
    "        \"answer\": output[\"answer\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オフライン評価の実装・実行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'elderly-cheese-14' at:\n",
      "https://smith.langchain.com/o/64d2ddf6-fc4f-4ab5-98d6-5a5e505bb610/datasets/715f3375-7106-446b-a306-fb26447008a7/compare?selectedSessions=0d75c567-015c-4551-a477-900dbea78189\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Error running evaluator <DynamicRunEvaluator evaluate> on run 53af9879-9752-49f5-8f8d-603398401aaa: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1576, in _request\n",
      "    response = await self._client.send(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpx/_client.py\", line 1629, in send\n",
      "    response = await self._send_handling_auth(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/anyio/streams/tls.py\", line 204, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/anyio/streams/tls.py\", line 147, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 1289, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/usr/local/lib/python3.10/asyncio/locks.py\", line 211, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "  File \"/usr/local/lib/python3.10/asyncio/mixins.py\", line 30, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x7f09dd5a2f20 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_20254/3667830247.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "  File \"/usr/local/lib/python3.10/asyncio/futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/usr/local/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/ragas/metrics/_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/usr/local/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1600, in _request\n",
      "    return await self._retry_request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1610, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "1it [00:11, 11.60s/it]Error running evaluator <DynamicRunEvaluator evaluate> on run 14ebc50d-a7ef-460f-b36c-aec168e4a33d: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1576, in _request\n",
      "    response = await self._client.send(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpx/_client.py\", line 1629, in send\n",
      "    response = await self._send_handling_auth(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/anyio/streams/tls.py\", line 204, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/anyio/streams/tls.py\", line 147, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 1289, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/usr/local/lib/python3.10/asyncio/locks.py\", line 211, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "  File \"/usr/local/lib/python3.10/asyncio/mixins.py\", line 30, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x7f09aadddf00 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/tmp/ipykernel_20254/3667830247.py\", line 25, in evaluate\n",
      "    score = self.metric.score(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/ragas/metrics/base.py\", line 106, in score\n",
      "    raise e\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/ragas/metrics/base.py\", line 102, in score\n",
      "    score = loop.run_until_complete(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "  File \"/usr/local/lib/python3.10/asyncio/futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/usr/local/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/ragas/metrics/_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/ragas/llms/base.py\", line 98, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/usr/local/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/ragas/llms/base.py\", line 180, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 801, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 761, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/usr/local/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 937, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1600, in _request\n",
      "    return await self._retry_request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1610, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "4it [00:36,  9.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.contexts</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.contexts</th>\n",
       "      <th>reference.ground_truth</th>\n",
       "      <th>feedback.context_precision</th>\n",
       "      <th>feedback.evaluate</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "      <th>feedback.answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What services does Naver offer with AI and cloud?</td>\n",
       "      <td>[page_content='# NAVER\\n\\nAll functionality re...</td>\n",
       "      <td>Naver offers a range of services related to AI...</td>\n",
       "      <td>None</td>\n",
       "      <td>[# NAVER\\n\\nAll functionality related to `Nave...</td>\n",
       "      <td>Naver offers a comprehensive suite of cloud se...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.099704</td>\n",
       "      <td>ed4f4d55-f07e-43b3-b0c9-b7b1726c161f</td>\n",
       "      <td>53af9879-9752-49f5-8f8d-603398401aaa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's a Python snippet for using HyperCLOVA X...</td>\n",
       "      <td>[page_content='# NAVER\\n\\nAll functionality re...</td>\n",
       "      <td>To use HyperCLOVA X in Naver Cloud, you can us...</td>\n",
       "      <td>None</td>\n",
       "      <td>[# NAVER\\n\\nAll functionality related to `Nave...</td>\n",
       "      <td>A Python snippet for using HyperCLOVA X in Nav...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.125752</td>\n",
       "      <td>b5132b1c-cf7a-455f-8a83-c2f81a042cc5</td>\n",
       "      <td>14ebc50d-a7ef-460f-b36c-aec168e4a33d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What models does GigaChat LLM provide?</td>\n",
       "      <td>[page_content='# Salute Devices\\n\\nSalute Devi...</td>\n",
       "      <td>GigaChat LLM provides chat models, LLMs (Large...</td>\n",
       "      <td>None</td>\n",
       "      <td>[# Salute Devices\\n\\nSalute Devices provides G...</td>\n",
       "      <td>GigaChat LLM provides models for chat and embe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.159430</td>\n",
       "      <td>e2f4a563-bd5d-42ab-854f-eac8cb0a780a</td>\n",
       "      <td>0ffc6d99-2687-4b6d-90f9-22840325f9da</td>\n",
       "      <td>0.899094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the purpose of the chat model in the C...</td>\n",
       "      <td>[page_content='# Cohere\\n\\n&gt;[Cohere](https://c...</td>\n",
       "      <td>The purpose of the chat model in the Cohere in...</td>\n",
       "      <td>None</td>\n",
       "      <td>[# Cohere\\n\\n&gt;[Cohere](https://cohere.ai/about...</td>\n",
       "      <td>The purpose of the chat model in the Cohere in...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.923903</td>\n",
       "      <td>57def430-7fb8-4f82-a50c-9bffb329a78e</td>\n",
       "      <td>05a765e7-b880-4b9e-ae43-312cec5369ca</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults elderly-cheese-14>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "evaluate(\n",
    "    predict,\n",
    "    data=\"agent-book\",\n",
    "    evaluators=evaluators,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith を使ったオンライン評価の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィードバックボタンを表示する関数の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from langsmith import Client\n",
    "\n",
    "\n",
    "def display_feedback_buttons(run_id: UUID) -> None:\n",
    "    # GoodボタンとBadボタンを準備\n",
    "    good_button = widgets.Button(\n",
    "        description=\"Good\",\n",
    "        button_style=\"success\",\n",
    "        icon=\"thumbs-up\",\n",
    "    )\n",
    "    bad_button = widgets.Button(\n",
    "        description=\"Bad\",\n",
    "        button_style=\"danger\",\n",
    "        icon=\"thumbs-down\",\n",
    "    )\n",
    "\n",
    "    # クリックされた際に実行される関数を定義\n",
    "    def on_button_clicked(button: widgets.Button) -> None:\n",
    "        if button == good_button:\n",
    "            score = 1\n",
    "        elif button == bad_button:\n",
    "            score = 0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown button: {button}\")\n",
    "\n",
    "        client = Client()\n",
    "        client.create_feedback(run_id=run_id, key=\"thumbs\", score=score)\n",
    "        print(\"フィードバックを送信しました\")\n",
    "\n",
    "    # ボタンがクリックされた際にon_button_clicked関数を実行\n",
    "    good_button.on_click(on_button_clicked)\n",
    "    bad_button.on_click(on_button_clicked)\n",
    "\n",
    "    # ボタンを表示\n",
    "    display(good_button, bad_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィードバックボタンを表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChainは、大規模言語モデル（LLM）を活用したアプリケーションを開発するためのフレームワークです。このフレームワークは、LLMアプリケーションのライフサイクルの各段階を簡素化します。具体的には、以下のような機能があります。\n",
      "\n",
      "1. **開発**: LangChainのオープンソースコンポーネントやサードパーティの統合を使用してアプリケーションを構築できます。LangGraphを利用することで、状態を持つエージェントを構築し、ストリーミングや人間の介入をサポートします。\n",
      "\n",
      "2. **生産化**: LangSmithを使用してアプリケーションを検査、監視、評価し、継続的に最適化して自信を持ってデプロイできます。\n",
      "\n",
      "3. **デプロイ**: LangGraphアプリケーションを生産準備が整ったAPIやアシスタントに変換できます。\n",
      "\n",
      "LangChainは、LLMや関連技術（埋め込みモデルやベクターストアなど）に対する標準インターフェースを実装しており、数百のプロバイダーと統合されています。また、複数のオープンソースライブラリで構成されており、ユーザーは自分のニーズに応じてさまざまなコンポーネントを選択して使用できます。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333fb94c4bc84d68a8d9602593e52195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Good', icon='thumbs-up', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c713ed11d96c4186b369370404942ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Bad', icon='thumbs-down', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.tracers.context import collect_runs\n",
    "\n",
    "# LangSmithのトレースのID(Run ID)を取得するため、collect_runs関数を使用\n",
    "with collect_runs() as runs_cb:\n",
    "    output = chain.invoke(\"LangChainの概要を教えて\")\n",
    "    print(output[\"answer\"])\n",
    "    run_id = runs_cb.traced_runs[0].id\n",
    "\n",
    "display_feedback_buttons(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
