{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Advanced RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:34.489407Z",
     "iopub.status.busy": "2024-06-28T02:32:34.488775Z",
     "iopub.status.idle": "2024-06-28T02:32:34.491583Z",
     "shell.execute_reply": "2024-06-28T02:32:34.491086Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# from google.colab import userdata\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. „Éè„É≥„Ç∫„Ç™„É≥„ÅÆÊ∫ñÂÇô\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core==0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain-openai==0.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: langchain-community==0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: GitPython==3.1.43 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (3.1.43)\n",
      "Requirement already satisfied: langchain-chroma==0.1.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (0.1.4)\n",
      "Requirement already satisfied: tavily-python==0.5.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.3.0) (8.5.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.3.0) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.3.0) (24.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.3.0) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.3.0) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core==0.3.0) (4.12.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-openai==0.2.0) (0.9.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-openai==0.2.0) (1.55.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.3.0) (2.32.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.3.0) (3.11.13)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.3.0) (2.8.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.3.0) (1.26.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.3.0) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.3.0) (0.3.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community==0.3.0) (2.0.39)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from GitPython==3.1.43) (4.0.12)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-chroma==0.1.4) (0.115.11)\n",
      "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-chroma==0.1.4) (0.5.23)\n",
      "Requirement already satisfied: httpx in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from tavily-python==0.5.0) (0.28.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (1.18.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (25.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (0.3.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.0) (6.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (5.1.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.31.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.15.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (13.9.4)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.10.15)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.21.0)\n",
      "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.20.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (32.0.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.67.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.7.6)\n",
      "Requirement already satisfied: importlib-resources in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (6.5.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (7.7.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.3.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.52b0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.34.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.31.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.20.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0) (3.26.1)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain-chroma==0.1.4) (0.46.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython==3.1.43) (5.0.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx->tavily-python==0.5.0) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx->tavily-python==0.5.0) (3.10)\n",
      "Requirement already satisfied: anyio in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx->tavily-python==0.5.0) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx->tavily-python==0.5.0) (2025.1.31)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx->tavily-python==0.5.0) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.0) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.0->langchain-community==0.3.0) (0.3.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (1.0.0)\n",
      "Requirement already satisfied: sniffio in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core==0.3.0) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.0) (1.0.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.3.0) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community==0.3.0) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.0) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from anyio->httpx->tavily-python==0.5.0) (1.2.2)\n",
      "Requirement already satisfied: pyproject_hooks in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.17.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.9.0.post0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.9)\n",
      "Requirement already satisfied: requests-oauthlib in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.0.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.38.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.2.2)\n",
      "Requirement already satisfied: protobuf in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (5.29.3)\n",
      "Requirement already satisfied: coloredlogs in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.13.3)\n",
      "Requirement already satisfied: flatbuffers in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (25.2.10)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (8.6.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.69.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.52b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.6)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.29.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.5.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (8.1.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0) (1.0.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.0.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.21.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.6.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (15.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.4.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2025.3.0)\n",
      "Requirement already satisfied: filelock in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.17.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-core==0.3.0 langchain-openai==0.2.0 \\\n",
    "    langchain-community==0.3.0 GitPython==3.1.43 \\\n",
    "    langchain-chroma==0.1.4 tavily-python==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    return file_path.endswith(\".mdx\")\n",
    "\n",
    "\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
    "    repo_path=\"./langchain\",\n",
    "    branch=\"master\",\n",
    "    file_filter=file_filter,\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Metadata: {'source': 'cookbook/sql_db_qa.mdx', 'file_path': 'cookbook/sql_db_qa.mdx', 'file_name': 'sql_db_qa.mdx', 'file_type': '.mdx'}\n",
      "Content:\n",
      "# SQL Database Chain\n",
      "\n",
      "This example demonstrates the use of the `SQLDatabaseChain` for answering questions over a SQL database.\n",
      "\n",
      "Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. The `SQLDatabaseChain` can therefore be used with any SQL dialect supported by SQLAlchemy, such as MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, [Databricks](/docs/ecosystem/integrations/databricks.html) and SQLite. Please refer to the SQLAlchemy documentation for more information about requirement\n",
      "================================================================================\n",
      "Document 2:\n",
      "Metadata: {'source': 'docs/docs/introduction.mdx', 'file_path': 'docs/docs/introduction.mdx', 'file_name': 'introduction.mdx', 'file_type': '.mdx'}\n",
      "Content:\n",
      "---\n",
      "sidebar_position: 0\n",
      "sidebar_class_name: hidden\n",
      "---\n",
      "\n",
      "# Introduction\n",
      "\n",
      "**LangChain** is a framework for developing applications powered by large language models (LLMs).\n",
      "\n",
      "LangChain simplifies every stage of the LLM application lifecycle:\n",
      "- **Development**: Build your applications using LangChain's open-source [components](/docs/concepts) and [third-party integrations](/docs/integrations/providers/).\n",
      "Use [LangGraph](/docs/concepts/architecture/#langgraph) to build stateful agents with first-class\n",
      "================================================================================\n",
      "Document 3:\n",
      "Metadata: {'source': 'docs/docs/people.mdx', 'file_path': 'docs/docs/people.mdx', 'file_name': 'people.mdx', 'file_type': '.mdx'}\n",
      "Content:\n",
      "---\n",
      "hide_table_of_contents: true\n",
      "---\n",
      "\n",
      "import People from \"@theme/People\";\n",
      "\n",
      "# People\n",
      "\n",
      "There are some incredible humans from all over the world who have been instrumental in helping the LangChain community flourish üåê!\n",
      "\n",
      "This page highlights a few of those folks who have dedicated their time to the open-source repo in the form of direct contributions and reviews.\n",
      "\n",
      "## Top reviewers\n",
      "\n",
      "As LangChain has grown, the amount of surface area that maintainers cover has grown as well.\n",
      "\n",
      "Thank you to the followin\n",
      "================================================================================\n",
      "Document 4:\n",
      "Metadata: {'source': 'docs/docs/_templates/integration.mdx', 'file_path': 'docs/docs/_templates/integration.mdx', 'file_name': 'integration.mdx', 'file_type': '.mdx'}\n",
      "Content:\n",
      "[comment: Please, a reference example here \"docs/integrations/arxiv.md\"]::\n",
      "[comment: Use this template to create a new .md file in \"docs/integrations/\"]::\n",
      "\n",
      "# Title_REPLACE_ME\n",
      "\n",
      "[comment: Only one Tile/H1 is allowed!]::\n",
      "\n",
      ">\n",
      "[comment: Description: After reading this description, a reader should decide if this integration is good enough to try/follow reading OR]::\n",
      "[comment: go to read the next integration doc. ]::\n",
      "[comment: Description should include a link to the source for follow reading.]::\n",
      "\n",
      "## In\n",
      "================================================================================\n",
      "Document 5:\n",
      "Metadata: {'source': 'docs/docs/additional_resources/arxiv_references.mdx', 'file_path': 'docs/docs/additional_resources/arxiv_references.mdx', 'file_name': 'arxiv_references.mdx', 'file_type': '.mdx'}\n",
      "Content:\n",
      "# arXiv\n",
      "            \n",
      "LangChain implements the latest research in the field of Natural Language Processing.\n",
      "This page contains `arXiv` papers referenced in the LangChain Documentation, API Reference,\n",
      " Templates, and Cookbooks.\n",
      "\n",
      "From the opposite direction, scientists use `LangChain` in research and reference it in the research papers. \n",
      "\n",
      "`arXiv` papers with references to:\n",
      " [LangChain](https://arxiv.org/search/?query=langchain&searchtype=all&source=header) | [LangGraph](https://arxiv.org/search/?qu\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(documents[:5]):  # ÊúÄÂàù„ÅÆ5‰ª∂„ÇíË°®Á§∫\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(f\"Content:\\n{doc.page_content[:500]}\")  # ÊúÄÂàù„ÅÆ500ÊñáÂ≠ó„Å†„ÅëË°®Á§∫\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='# SQL Database Chain\n",
      "\n",
      "This example demonstrates the use of the `SQLDatabaseChain` for answering questions over a SQL database.\n",
      "\n",
      "Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. The `SQLDatabaseChain` can therefore be used with any SQL dialect supported by SQLAlchemy, such as MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, [Databricks](/docs/ecosystem/integrations/databricks.html) and SQLite. Please refer to the SQLAlchemy documentation for more information about requirements for connecting to your database. For example, a connection to MySQL requires an appropriate connector such as PyMySQL. A URI for a MySQL connection might look like: `mysql+pymysql://user:pass@some_mysql_db_address/db_name`.\n",
      "\n",
      "This demonstration uses SQLite and the example Chinook database.\n",
      "To set it up, follow the instructions on https://database.guide/2-sample-databases-sqlite/, placing the `.db` file in a notebooks folder at the root of this repository.\n",
      "\n",
      "\n",
      "```python\n",
      "from langchain_openai import OpenAI\n",
      "from langchain_community.utilities import SQLDatabase\n",
      "from langchain_experimental.sql import SQLDatabaseChain\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\")\n",
      "llm = OpenAI(temperature=0, verbose=True)\n",
      "```\n",
      "\n",
      "**NOTE:** For data-sensitive projects, you can specify `return_direct=True` in the `SQLDatabaseChain` initialization to directly return the output of the SQL query without any additional formatting. This prevents the LLM from seeing any contents within the database. Note, however, the LLM still has access to the database scheme (i.e. dialect, table and key names) by default.\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain.run(\"How many employees are there?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    How many employees are there?\n",
      "    SQLQuery:\n",
      "\n",
      "    /workspace/langchain/langchain/sql_database.py:191: SAWarning: Dialect sqlite+pysqlite does *not* support Decimal objects natively, and SQLAlchemy must convert from floating point - rounding errors and other issues may occur. Please consider storing Decimal numbers as strings or integers on this platform for lossless storage.\n",
      "      sample_rows = connection.execute(command)\n",
      "\n",
      "\n",
      "    SELECT COUNT(*) FROM \"Employee\";\n",
      "    SQLResult: [(8,)]\n",
      "    Answer:There are 8 employees.\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    'There are 8 employees.'\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "## Use Query Checker\n",
      "Sometimes the Language Model generates invalid SQL with small mistakes that can be self-corrected using the same technique used by the SQL Database Agent to try and fix the SQL using the LLM. You can simply specify this option when creating the chain:\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, use_query_checker=True)\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain.run(\"How many albums by Aerosmith?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    How many albums by Aerosmith?\n",
      "    SQLQuery:SELECT COUNT(*) FROM Album WHERE ArtistId = 3;\n",
      "    SQLResult: [(1,)]\n",
      "    Answer:There is 1 album by Aerosmith.\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    'There is 1 album by Aerosmith.'\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "## Customize Prompt\n",
      "You can also customize the prompt that is used. Here is an example prompting it to understand that foobar is the same as the Employee table\n",
      "\n",
      "\n",
      "```python\n",
      "from langchain.prompts.prompt import PromptTemplate\n",
      "\n",
      "_DEFAULT_TEMPLATE = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
      "Use the following format:\n",
      "\n",
      "Question: \"Question here\"\n",
      "SQLQuery: \"SQL Query to run\"\n",
      "SQLResult: \"Result of the SQLQuery\"\n",
      "Answer: \"Final answer here\"\n",
      "\n",
      "Only use the following tables:\n",
      "\n",
      "{table_info}\n",
      "\n",
      "If someone asks for the table foobar, they really mean the employee table.\n",
      "\n",
      "Question: {input}\"\"\"\n",
      "PROMPT = PromptTemplate(\n",
      "    input_variables=[\"input\", \"table_info\", \"dialect\"], template=_DEFAULT_TEMPLATE\n",
      ")\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain = SQLDatabaseChain.from_llm(llm, db, prompt=PROMPT, verbose=True)\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain.run(\"How many employees are there in the foobar table?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    How many employees are there in the foobar table?\n",
      "    SQLQuery:SELECT COUNT(*) FROM Employee;\n",
      "    SQLResult: [(8,)]\n",
      "    Answer:There are 8 employees in the foobar table.\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    'There are 8 employees in the foobar table.'\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "## Return Intermediate Steps\n",
      "\n",
      "You can also return the intermediate steps of the SQLDatabaseChain. This allows you to access the SQL statement that was generated, as well as the result of running that against the SQL Database.\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain = SQLDatabaseChain.from_llm(llm, db, prompt=PROMPT, verbose=True, use_query_checker=True, return_intermediate_steps=True)\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "result = db_chain(\"How many employees are there in the foobar table?\")\n",
      "result[\"intermediate_steps\"]\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    How many employees are there in the foobar table?\n",
      "    SQLQuery:SELECT COUNT(*) FROM Employee;\n",
      "    SQLResult: [(8,)]\n",
      "    Answer:There are 8 employees in the foobar table.\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    [{'input': 'How many employees are there in the foobar table?\\nSQLQuery:SELECT COUNT(*) FROM Employee;\\nSQLResult: [(8,)]\\nAnswer:',\n",
      "      'top_k': '5',\n",
      "      'dialect': 'sqlite',\n",
      "      'table_info': '\\nCREATE TABLE \"Artist\" (\\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Artist table:\\nArtistId\\tName\\n1\\tAC/DC\\n2\\tAccept\\n3\\tAerosmith\\n*/\\n\\n\\nCREATE TABLE \"Employee\" (\\n\\t\"EmployeeId\" INTEGER NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\n\\t\"Title\" NVARCHAR(30), \\n\\t\"ReportsTo\" INTEGER, \\n\\t\"BirthDate\" DATETIME, \\n\\t\"HireDate\" DATETIME, \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60), \\n\\tPRIMARY KEY (\"EmployeeId\"), \\n\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Employee table:\\nEmployeeId\\tLastName\\tFirstName\\tTitle\\tReportsTo\\tBirthDate\\tHireDate\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\n1\\tAdams\\tAndrew\\tGeneral Manager\\tNone\\t1962-02-18 00:00:00\\t2002-08-14 00:00:00\\t11120 Jasper Ave NW\\tEdmonton\\tAB\\tCanada\\tT5K 2N1\\t+1 (780) 428-9482\\t+1 (780) 428-3457\\tandrew@chinookcorp.com\\n2\\tEdwards\\tNancy\\tSales Manager\\t1\\t1958-12-08 00:00:00\\t2002-05-01 00:00:00\\t825 8 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 2T3\\t+1 (403) 262-3443\\t+1 (403) 262-3322\\tnancy@chinookcorp.com\\n3\\tPeacock\\tJane\\tSales Support Agent\\t2\\t1973-08-29 00:00:00\\t2002-04-01 00:00:00\\t1111 6 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 5M5\\t+1 (403) 262-3443\\t+1 (403) 262-6712\\tjane@chinookcorp.com\\n*/\\n\\n\\nCREATE TABLE \"Genre\" (\\n\\t\"GenreId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"GenreId\")\\n)\\n\\n/*\\n3 rows from Genre table:\\nGenreId\\tName\\n1\\tRock\\n2\\tJazz\\n3\\tMetal\\n*/\\n\\n\\nCREATE TABLE \"MediaType\" (\\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"MediaTypeId\")\\n)\\n\\n/*\\n3 rows from MediaType table:\\nMediaTypeId\\tName\\n1\\tMPEG audio file\\n2\\tProtected AAC audio file\\n3\\tProtected MPEG-4 video file\\n*/\\n\\n\\nCREATE TABLE \"Playlist\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"PlaylistId\")\\n)\\n\\n/*\\n3 rows from Playlist table:\\nPlaylistId\\tName\\n1\\tMusic\\n2\\tMovies\\n3\\tTV Shows\\n*/\\n\\n\\nCREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Customer\" (\\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"FirstName\" NVARCHAR(40) NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"Company\" NVARCHAR(80), \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60) NOT NULL, \\n\\t\"SupportRepId\" INTEGER, \\n\\tPRIMARY KEY (\"CustomerId\"), \\n\\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLu√≠s\\tGon√ßalves\\tEmbraer - Empresa Brasileira de Aeron√°utica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\tS√£o Jos√© dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\tluisg@embraer.com.br\\t3\\n2\\tLeonie\\tK√∂hler\\tNone\\tTheodor-Heuss-Stra√üe 34\\tStuttgart\\tNone\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFran√ßois\\tTremblay\\tNone\\t1498 rue B√©langer\\tMontr√©al\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\tNone\\tftremblay@gmail.com\\t3\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Stra√üe 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllev√•lsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGr√©trystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/\\n\\n\\nCREATE TABLE \"Track\" (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL, \\n\\t\"AlbumId\" INTEGER, \\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"GenreId\" INTEGER, \\n\\t\"Composer\" NVARCHAR(220), \\n\\t\"Milliseconds\" INTEGER NOT NULL, \\n\\t\"Bytes\" INTEGER, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"TrackId\"), \\n\\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \\n\\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \\n\\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\\n)\\n\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tAlbumId\\tMediaTypeId\\tGenreId\\tComposer\\tMilliseconds\\tBytes\\tUnitPrice\\n1\\tFor Those About To Rock (We Salute You)\\t1\\t1\\t1\\tAngus Young, Malcolm Young, Brian Johnson\\t343719\\t11170334\\t0.99\\n2\\tBalls to the Wall\\t2\\t2\\t1\\tNone\\t342562\\t5510424\\t0.99\\n3\\tFast As a Shark\\t3\\t2\\t1\\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\\t230619\\t3990994\\t0.99\\n*/\\n\\n\\nCREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/\\n\\n\\nCREATE TABLE \"PlaylistTrack\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"PlaylistId\", \"TrackId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"PlaylistId\") REFERENCES \"Playlist\" (\"PlaylistId\")\\n)\\n\\n/*\\n3 rows from PlaylistTrack table:\\nPlaylistId\\tTrackId\\n1\\t3402\\n1\\t3389\\n1\\t3390\\n*/',\n",
      "      'stop': ['\\nSQLResult:']},\n",
      "     'SELECT COUNT(*) FROM Employee;',\n",
      "     {'query': 'SELECT COUNT(*) FROM Employee;', 'dialect': 'sqlite'},\n",
      "     'SELECT COUNT(*) FROM Employee;',\n",
      "     '[(8,)]']\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "## Adding Memory\n",
      "\n",
      "How to add memory to a SQLDatabaseChain:\n",
      "\n",
      "```python\n",
      "from langchain_openai import OpenAI\n",
      "from langchain_community.utilities import SQLDatabase\n",
      "from langchain_experimental.sql import SQLDatabaseChain\n",
      "```\n",
      "\n",
      "Set up the SQLDatabase and LLM\n",
      "\n",
      "```python\n",
      "db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\")\n",
      "llm = OpenAI(temperature=0, verbose=True)\n",
      "```\n",
      "\n",
      "Set up the memory\n",
      "\n",
      "```python\n",
      "from langchain.memory import ConversationBufferMemory\n",
      "memory = ConversationBufferMemory()\n",
      "```\n",
      "\n",
      "Now we need to add a place for memory in the prompt template\n",
      "\n",
      "```python\n",
      "from langchain.prompts import PromptTemplate\n",
      "PROMPT_SUFFIX = \"\"\"Only use the following tables:\n",
      "{table_info}\n",
      "\n",
      "Previous Conversation:\n",
      "{history}\n",
      "\n",
      "Question: {input}\"\"\"\n",
      "\n",
      "_DEFAULT_TEMPLATE = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Unless the user specifies in his question a specific number of examples he wishes to obtain, always limit your query to at most {top_k} results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "PROMPT = PromptTemplate.from_template(\n",
      "    _DEFAULT_TEMPLATE + PROMPT_SUFFIX,\n",
      ")\n",
      "```\n",
      "\n",
      "Now let's create and run out chain\n",
      "\n",
      "```python\n",
      "db_chain = SQLDatabaseChain.from_llm(llm, db, prompt=PROMPT, verbose=True, memory=memory)\n",
      "db_chain.run(\"name one employee\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    name one employee\n",
      "    SQLQuery:SELECT FirstName, LastName FROM Employee LIMIT 1\n",
      "    SQLResult: [('Andrew', 'Adams')]\n",
      "    Answer:Andrew Adams\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    'Andrew Adams'\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "```python\n",
      "db_chain.run(\"how many letters in their name?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    how many letters in their name?\n",
      "    SQLQuery:SELECT LENGTH(FirstName) + LENGTH(LastName) AS 'NameLength' FROM Employee WHERE FirstName = 'Andrew' AND LastName = 'Adams'\n",
      "    SQLResult: [(11,)]\n",
      "    Answer:Andrew Adams has 11 letters in their name.\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    'Andrew Adams has 11 letters in their name.'\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "\n",
      "## Choosing how to limit the number of rows returned\n",
      "If you are querying for several rows of a table you can select the maximum number of results you want to get by using the 'top_k' parameter (default is 10). This is useful for avoiding query results that exceed the prompt max length or consume tokens unnecessarily.\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, use_query_checker=True, top_k=3)\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain.run(\"What are some example tracks by composer Johann Sebastian Bach?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    What are some example tracks by composer Johann Sebastian Bach?\n",
      "    SQLQuery:SELECT Name FROM Track WHERE Composer = 'Johann Sebastian Bach' LIMIT 3\n",
      "    SQLResult: [('Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace',), ('Aria Mit 30 Ver√§nderungen, BWV 988 \"Goldberg Variations\": Aria',), ('Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude',)]\n",
      "    Answer:Examples of tracks by Johann Sebastian Bach are Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace, Aria Mit 30 Ver√§nderungen, BWV 988 \"Goldberg Variations\": Aria, and Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude.\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    'Examples of tracks by Johann Sebastian Bach are Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace, Aria Mit 30 Ver√§nderungen, BWV 988 \"Goldberg Variations\": Aria, and Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude.'\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "## Adding example rows from each table\n",
      "Sometimes, the format of the data is not obvious and it is optimal to include a sample of rows from the tables in the prompt to allow the LLM to understand the data before providing a final query. Here we will use this feature to let the LLM know that artists are saved with their full names by providing two rows from the `Track` table.\n",
      "\n",
      "\n",
      "```python\n",
      "db = SQLDatabase.from_uri(\n",
      "    \"sqlite:///../../../../notebooks/Chinook.db\",\n",
      "    include_tables=['Track'], # we include only one table to save tokens in the prompt :)\n",
      "    sample_rows_in_table_info=2)\n",
      "```\n",
      "\n",
      "The sample rows are added to the prompt after each corresponding table's column information:\n",
      "\n",
      "\n",
      "```python\n",
      "print(db.table_info)\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "    CREATE TABLE \"Track\" (\n",
      "    \t\"TrackId\" INTEGER NOT NULL,\n",
      "    \t\"Name\" NVARCHAR(200) NOT NULL,\n",
      "    \t\"AlbumId\" INTEGER,\n",
      "    \t\"MediaTypeId\" INTEGER NOT NULL,\n",
      "    \t\"GenreId\" INTEGER,\n",
      "    \t\"Composer\" NVARCHAR(220),\n",
      "    \t\"Milliseconds\" INTEGER NOT NULL,\n",
      "    \t\"Bytes\" INTEGER,\n",
      "    \t\"UnitPrice\" NUMERIC(10, 2) NOT NULL,\n",
      "    \tPRIMARY KEY (\"TrackId\"),\n",
      "    \tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"),\n",
      "    \tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"),\n",
      "    \tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\n",
      "    )\n",
      "\n",
      "    /*\n",
      "    2 rows from Track table:\n",
      "    TrackId\tName\tAlbumId\tMediaTypeId\tGenreId\tComposer\tMilliseconds\tBytes\tUnitPrice\n",
      "    1\tFor Those About To Rock (We Salute You)\t1\t1\t1\tAngus Young, Malcolm Young, Brian Johnson\t343719\t11170334\t0.99\n",
      "    2\tBalls to the Wall\t2\t2\t1\tNone\t342562\t5510424\t0.99\n",
      "    */\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain = SQLDatabaseChain.from_llm(llm, db, use_query_checker=True, verbose=True)\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain.run(\"What are some example tracks by Bach?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    What are some example tracks by Bach?\n",
      "    SQLQuery:SELECT \"Name\", \"Composer\" FROM \"Track\" WHERE \"Composer\" LIKE '%Bach%' LIMIT 5\n",
      "    SQLResult: [('American Woman', 'B. Cummings/G. Peterson/M.J. Kale/R. Bachman'), ('Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace', 'Johann Sebastian Bach'), ('Aria Mit 30 Ver√§nderungen, BWV 988 \"Goldberg Variations\": Aria', 'Johann Sebastian Bach'), ('Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude', 'Johann Sebastian Bach'), ('Toccata and Fugue in D Minor, BWV 565: I. Toccata', 'Johann Sebastian Bach')]\n",
      "    Answer:Tracks by Bach include 'American Woman', 'Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace', 'Aria Mit 30 Ver√§nderungen, BWV 988 \"Goldberg Variations\": Aria', 'Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude', and 'Toccata and Fugue in D Minor, BWV 565: I. Toccata'.\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    'Tracks by Bach include \\'American Woman\\', \\'Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\\', \\'Aria Mit 30 Ver√§nderungen, BWV 988 \"Goldberg Variations\": Aria\\', \\'Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude\\', and \\'Toccata and Fugue in D Minor, BWV 565: I. Toccata\\'.'\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "### Custom Table Info\n",
      "In some cases, it can be useful to provide custom table information instead of using the automatically generated table definitions and the first `sample_rows_in_table_info` sample rows. For example, if you know that the first few rows of a table are uninformative, it could help to manually provide example rows that are more diverse or provide more information to the model. It is also possible to limit the columns that will be visible to the model if there are unnecessary columns.\n",
      "\n",
      "This information can be provided as a dictionary with table names as the keys and table information as the values. For example, let's provide a custom definition and sample rows for the Track table with only a few columns:\n",
      "\n",
      "\n",
      "```python\n",
      "custom_table_info = {\n",
      "    \"Track\": \"\"\"CREATE TABLE Track (\n",
      "\t\"TrackId\" INTEGER NOT NULL,\n",
      "\t\"Name\" NVARCHAR(200) NOT NULL,\n",
      "\t\"Composer\" NVARCHAR(220),\n",
      "\tPRIMARY KEY (\"TrackId\")\n",
      ")\n",
      "/*\n",
      "3 rows from Track table:\n",
      "TrackId\tName\tComposer\n",
      "1\tFor Those About To Rock (We Salute You)\tAngus Young, Malcolm Young, Brian Johnson\n",
      "2\tBalls to the Wall\tNone\n",
      "3\tMy favorite song ever\tThe coolest composer of all time\n",
      "*/\"\"\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "db = SQLDatabase.from_uri(\n",
      "    \"sqlite:///../../../../notebooks/Chinook.db\",\n",
      "    include_tables=['Track', 'Playlist'],\n",
      "    sample_rows_in_table_info=2,\n",
      "    custom_table_info=custom_table_info)\n",
      "\n",
      "print(db.table_info)\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "    CREATE TABLE \"Playlist\" (\n",
      "    \t\"PlaylistId\" INTEGER NOT NULL,\n",
      "    \t\"Name\" NVARCHAR(120),\n",
      "    \tPRIMARY KEY (\"PlaylistId\")\n",
      "    )\n",
      "\n",
      "    /*\n",
      "    2 rows from Playlist table:\n",
      "    PlaylistId\tName\n",
      "    1\tMusic\n",
      "    2\tMovies\n",
      "    */\n",
      "\n",
      "    CREATE TABLE Track (\n",
      "    \t\"TrackId\" INTEGER NOT NULL,\n",
      "    \t\"Name\" NVARCHAR(200) NOT NULL,\n",
      "    \t\"Composer\" NVARCHAR(220),\n",
      "    \tPRIMARY KEY (\"TrackId\")\n",
      "    )\n",
      "    /*\n",
      "    3 rows from Track table:\n",
      "    TrackId\tName\tComposer\n",
      "    1\tFor Those About To Rock (We Salute You)\tAngus Young, Malcolm Young, Brian Johnson\n",
      "    2\tBalls to the Wall\tNone\n",
      "    3\tMy favorite song ever\tThe coolest composer of all time\n",
      "    */\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "Note how our custom table definition and sample rows for `Track` overrides the `sample_rows_in_table_info` parameter. Tables that are not overridden by `custom_table_info`, in this example `Playlist`, will have their table info gathered automatically as usual.\n",
      "\n",
      "\n",
      "```python\n",
      "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
      "db_chain.run(\"What are some example tracks by Bach?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    What are some example tracks by Bach?\n",
      "    SQLQuery:SELECT \"Name\" FROM Track WHERE \"Composer\" LIKE '%Bach%' LIMIT 5;\n",
      "    SQLResult: [('American Woman',), ('Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace',), ('Aria Mit 30 Ver√§nderungen, BWV 988 \"Goldberg Variations\": Aria',), ('Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude',), ('Toccata and Fugue in D Minor, BWV 565: I. Toccata',)]\n",
      "    Answer:text='You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\n\\nUse the following format:\\n\\nQuestion: \"Question here\"\\nSQLQuery: \"SQL Query to run\"\\nSQLResult: \"Result of the SQLQuery\"\\nAnswer: \"Final answer here\"\\n\\nOnly use the following tables:\\n\\nCREATE TABLE \"Playlist\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"PlaylistId\")\\n)\\n\\n/*\\n2 rows from Playlist table:\\nPlaylistId\\tName\\n1\\tMusic\\n2\\tMovies\\n*/\\n\\nCREATE TABLE Track (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL,\\n\\t\"Composer\" NVARCHAR(220),\\n\\tPRIMARY KEY (\"TrackId\")\\n)\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tComposer\\n1\\tFor Those About To Rock (We Salute You)\\tAngus Young, Malcolm Young, Brian Johnson\\n2\\tBalls to the Wall\\tNone\\n3\\tMy favorite song ever\\tThe coolest composer of all time\\n*/\\n\\nQuestion: What are some example tracks by Bach?\\nSQLQuery:SELECT \"Name\" FROM Track WHERE \"Composer\" LIKE \\'%Bach%\\' LIMIT 5;\\nSQLResult: [(\\'American Woman\\',), (\\'Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\\',), (\\'Aria Mit 30 Ver√§nderungen, BWV 988 \"Goldberg Variations\": Aria\\',), (\\'Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude\\',), (\\'Toccata and Fugue in D Minor, BWV 565: I. Toccata\\',)]\\nAnswer:'\n",
      "    You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
      "    Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
      "    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
      "    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "    Use the following format:\n",
      "\n",
      "    Question: \"Question here\"\n",
      "    SQLQuery: \"SQL Query to run\"\n",
      "    SQLResult: \"Result of the SQLQuery\"\n",
      "    Answer: \"Final answer here\"\n",
      "\n",
      "    Only use the following tables:\n",
      "\n",
      "    CREATE TABLE \"Playlist\" (\n",
      "    \t\"PlaylistId\" INTEGER NOT NULL,\n",
      "    \t\"Name\" NVARCHAR(120),\n",
      "    \tPRIMARY KEY (\"PlaylistId\")\n",
      "    )\n",
      "\n",
      "    /*\n",
      "    2 rows from Playlist table:\n",
      "    PlaylistId\tName\n",
      "    1\tMusic\n",
      "    2\tMovies\n",
      "    */\n",
      "\n",
      "    CREATE TABLE Track (\n",
      "    \t\"TrackId\" INTEGER NOT NULL,\n",
      "    \t\"Name\" NVARCHAR(200) NOT NULL,\n",
      "    \t\"Composer\" NVARCHAR(220),\n",
      "    \tPRIMARY KEY (\"TrackId\")\n",
      "    )\n",
      "    /*\n",
      "    3 rows from Track table:\n",
      "    TrackId\tName\tComposer\n",
      "    1\tFor Those About To Rock (We Salute You)\tAngus Young, Malcolm Young, Brian Johnson\n",
      "    2\tBalls to the Wall\tNone\n",
      "    3\tMy favorite song ever\tThe coolest composer of all time\n",
      "    */\n",
      "\n",
      "    Question: What are some example tracks by Bach?\n",
      "    SQLQuery:SELECT \"Name\" FROM Track WHERE \"Composer\" LIKE '%Bach%' LIMIT 5;\n",
      "    SQLResult: [('American Woman',), ('Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace',), ('Aria Mit 30 Ver√§nderungen, BWV 988 \"Goldberg Variations\": Aria',), ('Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude',), ('Toccata and Fugue in D Minor, BWV 565: I. Toccata',)]\n",
      "    Answer:\n",
      "    {'input': 'What are some example tracks by Bach?\\nSQLQuery:SELECT \"Name\" FROM Track WHERE \"Composer\" LIKE \\'%Bach%\\' LIMIT 5;\\nSQLResult: [(\\'American Woman\\',), (\\'Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\\',), (\\'Aria Mit 30 Ver√§nderungen, BWV 988 \"Goldberg Variations\": Aria\\',), (\\'Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude\\',), (\\'Toccata and Fugue in D Minor, BWV 565: I. Toccata\\',)]\\nAnswer:', 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE \"Playlist\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"PlaylistId\")\\n)\\n\\n/*\\n2 rows from Playlist table:\\nPlaylistId\\tName\\n1\\tMusic\\n2\\tMovies\\n*/\\n\\nCREATE TABLE Track (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL,\\n\\t\"Composer\" NVARCHAR(220),\\n\\tPRIMARY KEY (\"TrackId\")\\n)\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tComposer\\n1\\tFor Those About To Rock (We Salute You)\\tAngus Young, Malcolm Young, Brian Johnson\\n2\\tBalls to the Wall\\tNone\\n3\\tMy favorite song ever\\tThe coolest composer of all time\\n*/', 'stop': ['\\nSQLResult:']}\n",
      "    Examples of tracks by Bach include \"American Woman\", \"Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\", \"Aria Mit 30 Ver√§nderungen, BWV 988 'Goldberg Variations': Aria\", \"Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude\", and \"Toccata and Fugue in D Minor, BWV 565: I. Toccata\".\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    'Examples of tracks by Bach include \"American Woman\", \"Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\", \"Aria Mit 30 Ver√§nderungen, BWV 988 \\'Goldberg Variations\\': Aria\", \"Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Pr√©lude\", and \"Toccata and Fugue in D Minor, BWV 565: I. Toccata\".'\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "### SQL Views\n",
      "\n",
      "In some case, the table schema can be hidden behind a JSON or JSONB column. Adding row samples into the prompt might help won't always describe the data perfectly.\n",
      "\n",
      "For this reason, a custom SQL views can help.\n",
      "\n",
      "```sql\n",
      "CREATE VIEW accounts_v AS\n",
      "    select id, firstname, lastname, email, created_at, updated_at,\n",
      "        cast(stats->>'total_post' as int) as total_post,\n",
      "        cast(stats->>'total_comments' as int) as total_comments,\n",
      "        cast(stats->>'ltv' as int) as ltv\n",
      "\n",
      "        FROM accounts;\n",
      "```\n",
      "\n",
      "Then limit the tables visible from SQLDatabase to the created view.\n",
      "\n",
      "```python\n",
      "db = SQLDatabase.from_uri(\n",
      "    \"sqlite:///../../../../notebooks/Chinook.db\",\n",
      "    include_tables=['accounts_v']) # we include only the view\n",
      "```\n",
      "\n",
      "## SQLDatabaseSequentialChain\n",
      "\n",
      "Chain for querying SQL database that is a sequential chain.\n",
      "\n",
      "The chain is as follows:\n",
      "\n",
      "    1. Based on the query, determine which tables to use.\n",
      "    2. Based on those tables, call the normal SQL database chain.\n",
      "\n",
      "This is useful in cases where the number of tables in the database is large.\n",
      "\n",
      "\n",
      "```python\n",
      "from langchain_experimental.sql import SQLDatabaseSequentialChain\n",
      "db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\")\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "chain = SQLDatabaseSequentialChain.from_llm(llm, db, verbose=True)\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "chain.run(\"How many employees are also customers?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseSequentialChain chain...\n",
      "    Table names to use:\n",
      "    ['Employee', 'Customer']\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    How many employees are also customers?\n",
      "    SQLQuery:SELECT COUNT(*) FROM Employee e INNER JOIN Customer c ON e.EmployeeId = c.SupportRepId;\n",
      "    SQLResult: [(59,)]\n",
      "    Answer:59 employees are also customers.\n",
      "    > Finished chain.\n",
      "\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    '59 employees are also customers.'\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "## Using Local Language Models\n",
      "\n",
      "\n",
      "Sometimes you may not have the luxury of using OpenAI or other service-hosted large language model. You can, ofcourse, try to use the `SQLDatabaseChain` with a local model, but will quickly realize that most models you can run locally even with a large GPU struggle to generate the right output.\n",
      "\n",
      "\n",
      "```python\n",
      "import logging\n",
      "import torch\n",
      "from transformers import AutoTokenizer, GPT2TokenizerFast, pipeline, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
      "from langchain_huggingface import HuggingFacePipeline\n",
      "\n",
      "# Note: This model requires a large GPU, e.g. an 80GB A100. See documentation for other ways to run private non-OpenAI models.\n",
      "model_id = \"google/flan-ul2\"\n",
      "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, temperature=0)\n",
      "\n",
      "device_id = -1  # default to no-GPU, but use GPU and half precision mode if available\n",
      "if torch.cuda.is_available():\n",
      "    device_id = 0\n",
      "    try:\n",
      "        model = model.half()\n",
      "    except RuntimeError as exc:\n",
      "        logging.warn(f\"Could not run model in half precision mode: {str(exc)}\")\n",
      "\n",
      "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
      "pipe = pipeline(task=\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=1024, device=device_id)\n",
      "\n",
      "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "    Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:32<00:00,  4.11s/it]\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "\n",
      "```python\n",
      "from langchain_community.utilities import SQLDatabase\n",
      "from langchain_experimental.sql import SQLDatabaseChain\n",
      "\n",
      "db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\", include_tables=['Customer'])\n",
      "local_chain = SQLDatabaseChain.from_llm(local_llm, db, verbose=True, return_intermediate_steps=True, use_query_checker=True)\n",
      "```\n",
      "\n",
      "This model should work for very simple SQL queries, as long as you use the query checker as specified above, e.g.:\n",
      "\n",
      "\n",
      "```python\n",
      "local_chain(\"How many customers are there?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    How many customers are there?\n",
      "    SQLQuery:\n",
      "\n",
      "    /workspace/langchain/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "      warnings.warn(\n",
      "    /workspace/langchain/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "      warnings.warn(\n",
      "\n",
      "\n",
      "    SELECT count(*) FROM Customer\n",
      "    SQLResult: [(59,)]\n",
      "    Answer:\n",
      "\n",
      "    /workspace/langchain/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "      warnings.warn(\n",
      "\n",
      "\n",
      "    [59]\n",
      "    > Finished chain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    {'query': 'How many customers are there?',\n",
      "     'result': '[59]',\n",
      "     'intermediate_steps': [{'input': 'How many customers are there?\\nSQLQuery:SELECT count(*) FROM Customer\\nSQLResult: [(59,)]\\nAnswer:',\n",
      "       'top_k': '5',\n",
      "       'dialect': 'sqlite',\n",
      "       'table_info': '\\nCREATE TABLE \"Customer\" (\\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"FirstName\" NVARCHAR(40) NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"Company\" NVARCHAR(80), \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60) NOT NULL, \\n\\t\"SupportRepId\" INTEGER, \\n\\tPRIMARY KEY (\"CustomerId\"), \\n\\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLu√≠s\\tGon√ßalves\\tEmbraer - Empresa Brasileira de Aeron√°utica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\tS√£o Jos√© dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\tluisg@embraer.com.br\\t3\\n2\\tLeonie\\tK√∂hler\\tNone\\tTheodor-Heuss-Stra√üe 34\\tStuttgart\\tNone\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFran√ßois\\tTremblay\\tNone\\t1498 rue B√©langer\\tMontr√©al\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\tNone\\tftremblay@gmail.com\\t3\\n*/',\n",
      "       'stop': ['\\nSQLResult:']},\n",
      "      'SELECT count(*) FROM Customer',\n",
      "      {'query': 'SELECT count(*) FROM Customer', 'dialect': 'sqlite'},\n",
      "      'SELECT count(*) FROM Customer',\n",
      "      '[(59,)]']}\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "Even this relatively large model will most likely fail to generate more complicated SQL by itself. However, you can log its inputs and outputs so that you can hand-correct them and use the corrected examples for few-shot prompt examples later. In practice, you could log any executions of your chain that raise exceptions (as shown in the example below) or get direct user feedback in cases where the results are incorrect (but did not raise an exception).\n",
      "\n",
      "\n",
      "```bash\n",
      "poetry run pip install pyyaml langchain_chroma\n",
      "import yaml\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"bash\">\n",
      "\n",
      "```\n",
      "    huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "    To disable this warning, you can either:\n",
      "    \t- Avoid using `tokenizers` before the fork if possible\n",
      "    \t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "\n",
      "    11842.36s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\n",
      "\n",
      "    Requirement already satisfied: pyyaml in /workspace/langchain/.venv/lib/python3.9/site-packages (6.0)\n",
      "    Requirement already satisfied: chromadb in /workspace/langchain/.venv/lib/python3.9/site-packages (0.3.21)\n",
      "    Requirement already satisfied: pandas>=1.3 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (2.0.1)\n",
      "    Requirement already satisfied: requests>=2.28 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (2.28.2)\n",
      "    Requirement already satisfied: pydantic>=1.9 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (1.10.7)\n",
      "    Requirement already satisfied: hnswlib>=0.7 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (0.7.0)\n",
      "    Requirement already satisfied: clickhouse-connect>=0.5.7 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (0.5.20)\n",
      "    Requirement already satisfied: sentence-transformers>=2.2.2 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (2.2.2)\n",
      "    Requirement already satisfied: duckdb>=0.7.1 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (0.7.1)\n",
      "    Requirement already satisfied: fastapi>=0.85.1 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (0.95.1)\n",
      "    Requirement already satisfied: uvicorn[standard]>=0.18.3 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (0.21.1)\n",
      "    Requirement already satisfied: numpy>=1.21.6 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (1.24.3)\n",
      "    Requirement already satisfied: posthog>=2.4.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (3.0.1)\n",
      "    Requirement already satisfied: certifi in /workspace/langchain/.venv/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
      "    Requirement already satisfied: urllib3>=1.26 in /workspace/langchain/.venv/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
      "    Requirement already satisfied: pytz in /workspace/langchain/.venv/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3)\n",
      "    Requirement already satisfied: zstandard in /workspace/langchain/.venv/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
      "    Requirement already satisfied: lz4 in /workspace/langchain/.venv/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
      "    Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /workspace/langchain/.venv/lib/python3.9/site-packages (from fastapi>=0.85.1->chromadb) (0.26.1)\n",
      "    Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/langchain/.venv/lib/python3.9/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "    Requirement already satisfied: tzdata>=2022.1 in /workspace/langchain/.venv/lib/python3.9/site-packages (from pandas>=1.3->chromadb) (2023.3)\n",
      "    Requirement already satisfied: six>=1.5 in /workspace/langchain/.venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "    Requirement already satisfied: monotonic>=1.5 in /workspace/langchain/.venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "    Requirement already satisfied: backoff>=1.10.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "    Requirement already satisfied: typing-extensions>=4.2.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (4.5.0)\n",
      "    Requirement already satisfied: charset-normalizer<4,>=2 in /workspace/langchain/.venv/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.1.0)\n",
      "    Requirement already satisfied: idna<4,>=2.5 in /workspace/langchain/.venv/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "    Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.28.1)\n",
      "    Requirement already satisfied: tqdm in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.65.0)\n",
      "    Requirement already satisfied: torch>=1.6.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.13.1)\n",
      "    Requirement already satisfied: torchvision in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.14.1)\n",
      "    Requirement already satisfied: scikit-learn in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2)\n",
      "    Requirement already satisfied: scipy in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.9.3)\n",
      "    Requirement already satisfied: nltk in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (3.8.1)\n",
      "    Requirement already satisfied: sentencepiece in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.1.98)\n",
      "    Requirement already satisfied: huggingface-hub>=0.4.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.13.4)\n",
      "    Requirement already satisfied: click>=7.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "    Requirement already satisfied: h11>=0.8 in /workspace/langchain/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "    Requirement already satisfied: httptools>=0.5.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
      "    Requirement already satisfied: python-dotenv>=0.13 in /workspace/langchain/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "    Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "    Requirement already satisfied: watchfiles>=0.13 in /workspace/langchain/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "    Requirement already satisfied: websockets>=10.4 in /workspace/langchain/.venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.2)\n",
      "    Requirement already satisfied: filelock in /workspace/langchain/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.12.0)\n",
      "    Requirement already satisfied: packaging>=20.9 in /workspace/langchain/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (23.1)\n",
      "    Requirement already satisfied: anyio<5,>=3.4.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (3.6.2)\n",
      "    Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /workspace/langchain/.venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (11.7.99)\n",
      "    Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /workspace/langchain/.venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (8.5.0.96)\n",
      "    Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /workspace/langchain/.venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (11.10.3.66)\n",
      "    Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /workspace/langchain/.venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (11.7.99)\n",
      "    Requirement already satisfied: setuptools in /workspace/langchain/.venv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (67.7.1)\n",
      "    Requirement already satisfied: wheel in /workspace/langchain/.venv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (0.40.0)\n",
      "    Requirement already satisfied: regex!=2019.12.17 in /workspace/langchain/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2023.3.23)\n",
      "    Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /workspace/langchain/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.3)\n",
      "    Requirement already satisfied: joblib in /workspace/langchain/.venv/lib/python3.9/site-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
      "    Requirement already satisfied: threadpoolctl>=2.0.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
      "    Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (9.5.0)\n",
      "    Requirement already satisfied: sniffio>=1.1 in /workspace/langchain/.venv/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (1.3.0)\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "\n",
      "```python\n",
      "from typing import Dict\n",
      "\n",
      "QUERY = \"List all the customer first names that start with 'a'\"\n",
      "\n",
      "def _parse_example(result: Dict) -> Dict:\n",
      "    sql_cmd_key = \"sql_cmd\"\n",
      "    sql_result_key = \"sql_result\"\n",
      "    table_info_key = \"table_info\"\n",
      "    input_key = \"input\"\n",
      "    final_answer_key = \"answer\"\n",
      "\n",
      "    _example = {\n",
      "        \"input\": result.get(\"query\"),\n",
      "    }\n",
      "\n",
      "    steps = result.get(\"intermediate_steps\")\n",
      "    answer_key = sql_cmd_key # the first one\n",
      "    for step in steps:\n",
      "        # The steps are in pairs, a dict (input) followed by a string (output).\n",
      "        # Unfortunately there is no schema but you can look at the input key of the\n",
      "        # dict to see what the output is supposed to be\n",
      "        if isinstance(step, dict):\n",
      "            # Grab the table info from input dicts in the intermediate steps once\n",
      "            if table_info_key not in _example:\n",
      "                _example[table_info_key] = step.get(table_info_key)\n",
      "\n",
      "            if input_key in step:\n",
      "                if step[input_key].endswith(\"SQLQuery:\"):\n",
      "                    answer_key = sql_cmd_key # this is the SQL generation input\n",
      "                if step[input_key].endswith(\"Answer:\"):\n",
      "                    answer_key = final_answer_key # this is the final answer input\n",
      "            elif sql_cmd_key in step:\n",
      "                _example[sql_cmd_key] = step[sql_cmd_key]\n",
      "                answer_key = sql_result_key # this is SQL execution input\n",
      "        elif isinstance(step, str):\n",
      "            # The preceding element should have set the answer_key\n",
      "            _example[answer_key] = step\n",
      "    return _example\n",
      "\n",
      "example: any\n",
      "try:\n",
      "    result = local_chain(QUERY)\n",
      "    print(\"*** Query succeeded\")\n",
      "    example = _parse_example(result)\n",
      "except Exception as exc:\n",
      "    print(\"*** Query failed\")\n",
      "    result = {\n",
      "        \"query\": QUERY,\n",
      "        \"intermediate_steps\": exc.intermediate_steps\n",
      "    }\n",
      "    example = _parse_example(result)\n",
      "\n",
      "\n",
      "# print for now, in reality you may want to write this out to a YAML file or database for manual fix-ups offline\n",
      "yaml_example = yaml.dump(example, allow_unicode=True)\n",
      "print(\"\\n\" + yaml_example)\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    List all the customer first names that start with 'a'\n",
      "    SQLQuery:\n",
      "\n",
      "    /workspace/langchain/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "      warnings.warn(\n",
      "\n",
      "\n",
      "    SELECT firstname FROM customer WHERE firstname LIKE '%a%'\n",
      "    SQLResult: [('Fran√ßois',), ('Franti≈°ek',), ('Helena',), ('Astrid',), ('Daan',), ('Kara',), ('Eduardo',), ('Alexandre',), ('Fernanda',), ('Mark',), ('Frank',), ('Jack',), ('Dan',), ('Kathy',), ('Heather',), ('Frank',), ('Richard',), ('Patrick',), ('Julia',), ('Edward',), ('Martha',), ('Aaron',), ('Madalena',), ('Hannah',), ('Niklas',), ('Camille',), ('Marc',), ('Wyatt',), ('Isabelle',), ('Ladislav',), ('Lucas',), ('Johannes',), ('Stanis≈Çaw',), ('Joakim',), ('Emma',), ('Mark',), ('Manoj',), ('Puja',)]\n",
      "    Answer:\n",
      "\n",
      "    /workspace/langchain/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "      warnings.warn(\n",
      "\n",
      "\n",
      "    [('Fran√ßois', 'Frantiek', 'Helena', 'Astrid', 'Daan', 'Kara', 'Eduardo', 'Alexandre', 'Fernanda', 'Mark', 'Frank', 'Jack', 'Dan', 'Kathy', 'Heather', 'Frank', 'Richard', 'Patrick', 'Julia', 'Edward', 'Martha', 'Aaron', 'Madalena', 'Hannah', 'Niklas', 'Camille', 'Marc', 'Wyatt', 'Isabelle', 'Ladislav', 'Lucas', 'Johannes', 'Stanisaw', 'Joakim', 'Emma', 'Mark', 'Manoj', 'Puja']\n",
      "    > Finished chain.\n",
      "    *** Query succeeded\n",
      "\n",
      "    answer: '[(''Fran√ßois'', ''Frantiek'', ''Helena'', ''Astrid'', ''Daan'', ''Kara'',\n",
      "      ''Eduardo'', ''Alexandre'', ''Fernanda'', ''Mark'', ''Frank'', ''Jack'', ''Dan'',\n",
      "      ''Kathy'', ''Heather'', ''Frank'', ''Richard'', ''Patrick'', ''Julia'', ''Edward'',\n",
      "      ''Martha'', ''Aaron'', ''Madalena'', ''Hannah'', ''Niklas'', ''Camille'', ''Marc'',\n",
      "      ''Wyatt'', ''Isabelle'', ''Ladislav'', ''Lucas'', ''Johannes'', ''Stanisaw'', ''Joakim'',\n",
      "      ''Emma'', ''Mark'', ''Manoj'', ''Puja'']'\n",
      "    input: List all the customer first names that start with 'a'\n",
      "    sql_cmd: SELECT firstname FROM customer WHERE firstname LIKE '%a%'\n",
      "    sql_result: '[(''Fran√ßois'',), (''Franti≈°ek'',), (''Helena'',), (''Astrid'',), (''Daan'',),\n",
      "      (''Kara'',), (''Eduardo'',), (''Alexandre'',), (''Fernanda'',), (''Mark'',), (''Frank'',),\n",
      "      (''Jack'',), (''Dan'',), (''Kathy'',), (''Heather'',), (''Frank'',), (''Richard'',),\n",
      "      (''Patrick'',), (''Julia'',), (''Edward'',), (''Martha'',), (''Aaron'',), (''Madalena'',),\n",
      "      (''Hannah'',), (''Niklas'',), (''Camille'',), (''Marc'',), (''Wyatt'',), (''Isabelle'',),\n",
      "      (''Ladislav'',), (''Lucas'',), (''Johannes'',), (''Stanis≈Çaw'',), (''Joakim'',),\n",
      "      (''Emma'',), (''Mark'',), (''Manoj'',), (''Puja'',)]'\n",
      "    table_info: \"\\nCREATE TABLE \\\"Customer\\\" (\\n\\t\\\"CustomerId\\\" INTEGER NOT NULL, \\n\\t\\\n",
      "      \\\"FirstName\\\" NVARCHAR(40) NOT NULL, \\n\\t\\\"LastName\\\" NVARCHAR(20) NOT NULL, \\n\\t\\\n",
      "      \\\"Company\\\" NVARCHAR(80), \\n\\t\\\"Address\\\" NVARCHAR(70), \\n\\t\\\"City\\\" NVARCHAR(40),\\\n",
      "      \\ \\n\\t\\\"State\\\" NVARCHAR(40), \\n\\t\\\"Country\\\" NVARCHAR(40), \\n\\t\\\"PostalCode\\\" NVARCHAR(10),\\\n",
      "      \\ \\n\\t\\\"Phone\\\" NVARCHAR(24), \\n\\t\\\"Fax\\\" NVARCHAR(24), \\n\\t\\\"Email\\\" NVARCHAR(60)\\\n",
      "      \\ NOT NULL, \\n\\t\\\"SupportRepId\\\" INTEGER, \\n\\tPRIMARY KEY (\\\"CustomerId\\\"), \\n\\t\\\n",
      "      FOREIGN KEY(\\\"SupportRepId\\\") REFERENCES \\\"Employee\\\" (\\\"EmployeeId\\\")\\n)\\n\\n/*\\n\\\n",
      "      3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\t\\\n",
      "      City\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLu√≠s\\tGon√ßalves\\t\\\n",
      "      Embraer - Empresa Brasileira de Aeron√°utica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\t\\\n",
      "      S√£o Jos√© dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\t\\\n",
      "      luisg@embraer.com.br\\t3\\n2\\tLeonie\\tK√∂hler\\tNone\\tTheodor-Heuss-Stra√üe 34\\tStuttgart\\t\\\n",
      "      None\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFran√ßois\\t\\\n",
      "      Tremblay\\tNone\\t1498 rue B√©langer\\tMontr√©al\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\t\\\n",
      "      None\\tftremblay@gmail.com\\t3\\n*/\"\n",
      "\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "Run the snippet above a few times, or log exceptions in your deployed environment, to collect lots of examples of inputs, table_info and sql_cmd generated by your language model. The sql_cmd values will be incorrect and you can manually fix them up to build a collection of examples, e.g. here we are using YAML to keep a neat record of our inputs and corrected SQL output that we can build up over time.\n",
      "\n",
      "\n",
      "```python\n",
      "YAML_EXAMPLES = \"\"\"\n",
      "- input: How many customers are not from Brazil?\n",
      "  table_info: |\n",
      "    CREATE TABLE \"Customer\" (\n",
      "      \"CustomerId\" INTEGER NOT NULL,\n",
      "      \"FirstName\" NVARCHAR(40) NOT NULL,\n",
      "      \"LastName\" NVARCHAR(20) NOT NULL,\n",
      "      \"Company\" NVARCHAR(80),\n",
      "      \"Address\" NVARCHAR(70),\n",
      "      \"City\" NVARCHAR(40),\n",
      "      \"State\" NVARCHAR(40),\n",
      "      \"Country\" NVARCHAR(40),\n",
      "      \"PostalCode\" NVARCHAR(10),\n",
      "      \"Phone\" NVARCHAR(24),\n",
      "      \"Fax\" NVARCHAR(24),\n",
      "      \"Email\" NVARCHAR(60) NOT NULL,\n",
      "      \"SupportRepId\" INTEGER,\n",
      "      PRIMARY KEY (\"CustomerId\"),\n",
      "      FOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      "    )\n",
      "  sql_cmd: SELECT COUNT(*) FROM \"Customer\" WHERE NOT \"Country\" = \"Brazil\";\n",
      "  sql_result: \"[(54,)]\"\n",
      "  answer: 54 customers are not from Brazil.\n",
      "- input: list all the genres that start with 'r'\n",
      "  table_info: |\n",
      "    CREATE TABLE \"Genre\" (\n",
      "      \"GenreId\" INTEGER NOT NULL,\n",
      "      \"Name\" NVARCHAR(120),\n",
      "      PRIMARY KEY (\"GenreId\")\n",
      "    )\n",
      "\n",
      "    /*\n",
      "    3 rows from Genre table:\n",
      "    GenreId\tName\n",
      "    1\tRock\n",
      "    2\tJazz\n",
      "    3\tMetal\n",
      "    */\n",
      "  sql_cmd: SELECT \"Name\" FROM \"Genre\" WHERE \"Name\" LIKE 'r%';\n",
      "  sql_result: \"[('Rock',), ('Rock and Roll',), ('Reggae',), ('R&B/Soul',)]\"\n",
      "  answer: The genres that start with 'r' are Rock, Rock and Roll, Reggae and R&B/Soul.\n",
      "\"\"\"\n",
      "```\n",
      "\n",
      "Now that you have some examples (with manually corrected output SQL), you can do few-shot prompt seeding the usual way:\n",
      "\n",
      "\n",
      "```python\n",
      "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
      "from langchain.chains.sql_database.prompt import _sqlite_prompt, PROMPT_SUFFIX\n",
      "from langchain_huggingface import HuggingFaceEmbeddings\n",
      "from langchain.prompts.example_selector.semantic_similarity import SemanticSimilarityExampleSelector\n",
      "from langchain_chroma import Chroma\n",
      "\n",
      "example_prompt = PromptTemplate(\n",
      "    input_variables=[\"table_info\", \"input\", \"sql_cmd\", \"sql_result\", \"answer\"],\n",
      "    template=\"{table_info}\\n\\nQuestion: {input}\\nSQLQuery: {sql_cmd}\\nSQLResult: {sql_result}\\nAnswer: {answer}\",\n",
      ")\n",
      "\n",
      "examples_dict = yaml.safe_load(YAML_EXAMPLES)\n",
      "\n",
      "local_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "\n",
      "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
      "                        # This is the list of examples available to select from.\n",
      "                        examples_dict,\n",
      "                        # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
      "                        local_embeddings,\n",
      "                        # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
      "                        Chroma,  # type: ignore\n",
      "                        # This is the number of examples to produce and include per prompt\n",
      "                        k=min(3, len(examples_dict)),\n",
      "                    )\n",
      "\n",
      "few_shot_prompt = FewShotPromptTemplate(\n",
      "    example_selector=example_selector,\n",
      "    example_prompt=example_prompt,\n",
      "    prefix=_sqlite_prompt + \"Here are some examples:\",\n",
      "    suffix=PROMPT_SUFFIX,\n",
      "    input_variables=[\"table_info\", \"input\", \"top_k\"],\n",
      ")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "    Using embedded DuckDB without persistence: data will be transient\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "The model should do better now with this few-shot prompt, especially for inputs similar to the examples you have seeded it with.\n",
      "\n",
      "\n",
      "```python\n",
      "local_chain = SQLDatabaseChain.from_llm(local_llm, db, prompt=few_shot_prompt, use_query_checker=True, verbose=True, return_intermediate_steps=True)\n",
      "```\n",
      "\n",
      "\n",
      "```python\n",
      "result = local_chain(\"How many customers are from Brazil?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    How many customers are from Brazil?\n",
      "    SQLQuery:SELECT count(*) FROM Customer WHERE Country = \"Brazil\";\n",
      "    SQLResult: [(5,)]\n",
      "    Answer:[5]\n",
      "    > Finished chain.\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "\n",
      "```python\n",
      "result = local_chain(\"How many customers are not from Brazil?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    How many customers are not from Brazil?\n",
      "    SQLQuery:SELECT count(*) FROM customer WHERE country NOT IN (SELECT country FROM customer WHERE country = 'Brazil')\n",
      "    SQLResult: [(54,)]\n",
      "    Answer:54 customers are not from Brazil.\n",
      "    > Finished chain.\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "\n",
      "\n",
      "```python\n",
      "result = local_chain(\"How many customers are there in total?\")\n",
      "```\n",
      "\n",
      "<CodeOutputBlock lang=\"python\">\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "    > Entering new SQLDatabaseChain chain...\n",
      "    How many customers are there in total?\n",
      "    SQLQuery:SELECT count(*) FROM Customer;\n",
      "    SQLResult: [(59,)]\n",
      "    Answer:There are 59 customers in total.\n",
      "    > Finished chain.\n",
      "```\n",
      "\n",
      "</CodeOutputBlock>\n",
      "' metadata={'source': 'cookbook/sql_db_qa.mdx', 'file_path': 'cookbook/sql_db_qa.mdx', 'file_name': 'sql_db_qa.mdx', 'file_type': '.mdx'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain„ÅØ„ÄÅÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´ÔºàLLMÔºâ„ÇíÊ¥ªÁî®„Åó„Åü„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÈñãÁô∫„Åô„Çã„Åü„ÇÅ„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Åß„Åô„ÄÇ„Åì„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅØ„ÄÅLLM„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„É©„Ç§„Éï„Çµ„Ç§„ÇØ„É´„ÅÆÂêÑ„Çπ„ÉÜ„Éº„Ç∏„ÇíÁ∞°Á¥†Âåñ„Åó„Åæ„Åô„ÄÇÂÖ∑‰ΩìÁöÑ„Å´„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™Ê©üËÉΩ„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\n1. **ÈñãÁô∫**: LangChain„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇÑ„Çµ„Éº„Éâ„Éë„Éº„ÉÜ„Ç£Áµ±Âêà„Çí‰ΩøÁî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊßãÁØâ„Åß„Åç„Åæ„Åô„ÄÇLangGraph„ÇíÂà©Áî®„Åô„Çã„Åì„Å®„Åß„ÄÅÁä∂ÊÖã„ÇíÊåÅ„Å§„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÇíÊßãÁØâ„Åó„ÄÅ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„ÇÑ‰∫∫Èñì„ÅÆ‰ªãÂÖ•„Çí„Çµ„Éù„Éº„Éà„Åó„Åæ„Åô„ÄÇ\\n\\n2. **ÁîüÁî£Âåñ**: LangSmith„Çí‰ΩøÁî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊ§úÊüª„ÄÅÁõ£Ë¶ñ„ÄÅË©ï‰æ°„Åó„ÄÅÁ∂ôÁ∂öÁöÑ„Å´ÊúÄÈÅ©Âåñ„Åó„Å¶Ëá™‰ø°„ÇíÊåÅ„Å£„Å¶„Éá„Éó„É≠„Ç§„Åß„Åç„Åæ„Åô„ÄÇ\\n\\n3. **„Éá„Éó„É≠„Ç§**: LangGraph„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÁîüÁî£Ê∫ñÂÇô„ÅåÊï¥„Å£„ÅüAPI„ÇÑ„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Å´Â§âÊèõ„Åß„Åç„Åæ„Åô„ÄÇ\\n\\nLangChain„ÅØ„ÄÅLLM„ÇÑÈñ¢ÈÄ£ÊäÄË°ìÔºàÂüã„ÇÅËæº„Åø„É¢„Éá„É´„ÇÑ„Éô„ÇØ„Éà„É´„Çπ„Éà„Ç¢Ôºâ„Å´ÂØæ„Åô„ÇãÊ®ôÊ∫ñ„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ„ÇíÂÆüË£Ö„Åó„ÄÅÊï∞Áôæ„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Å®Áµ±Âêà„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅË§áÊï∞„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„É©„Ç§„Éñ„É©„É™„ÅßÊßãÊàê„Åï„Çå„Å¶„Åä„Çä„ÄÅ„É¶„Éº„Ç∂„Éº„ÅØËá™ÂàÜ„ÅÆ„Éã„Éº„Ç∫„Å´Âøú„Åò„Å¶„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇíÈÅ∏Êäû„Åó„Å¶‰ΩøÁî®„Åß„Åç„Åæ„Åô„ÄÇ'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "‰ª•‰∏ã„ÅÆÊñáËÑà„Å†„Åë„ÇíË∏è„Åæ„Åà„Å¶Ë≥™Âïè„Å´ÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
    "\n",
    "ÊñáËÑà: \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "Ë≥™Âïè: {question}\n",
    "''')\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": retriever,\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "chain.invoke(\"LangChain„ÅÆÊ¶ÇË¶Å„ÇíÊïô„Åà„Å¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Ê§úÁ¥¢„ÇØ„Ç®„É™„ÅÆÂ∑•Â§´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyDEÔºàHypothetical Document EmbeddingsÔºâ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "Ê¨°„ÅÆË≥™Âïè„Å´ÂõûÁ≠î„Åô„Çã‰∏ÄÊñá„ÇíÊõ∏„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
    "\n",
    "Ë≥™Âïè: {question}\n",
    "\"\"\")\n",
    "\n",
    "hypothetical_chain = hypothetical_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain„ÅØ„ÄÅÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´ÔºàLLMÔºâ„ÇíÊ¥ªÁî®„Åó„Åü„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÈñãÁô∫„Åô„Çã„Åü„ÇÅ„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Åß„Åô„ÄÇLangChain„ÅØ„ÄÅ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„É©„Ç§„Éï„Çµ„Ç§„ÇØ„É´„ÅÆÂêÑÊÆµÈöé„ÇíÁ∞°Á¥†Âåñ„Åó„Åæ„Åô„ÄÇÂÖ∑‰ΩìÁöÑ„Å´„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™Ê©üËÉΩ„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\n1. **ÈñãÁô∫**: LangChain„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇÑ„Çµ„Éº„Éâ„Éë„Éº„ÉÜ„Ç£„ÅÆÁµ±Âêà„Çí‰ΩøÁî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊßãÁØâ„Åß„Åç„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅLangGraph„ÇíÂà©Áî®„Åó„Å¶„ÄÅÁä∂ÊÖã„ÇíÊåÅ„Å§„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÇíÊßãÁØâ„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ\\n\\n2. **ÁîüÁî£Âåñ**: LangSmith„Çí‰ΩøÁî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊ§úÊüª„ÄÅÁõ£Ë¶ñ„ÄÅË©ï‰æ°„Åó„ÄÅÁ∂ôÁ∂öÁöÑ„Å´ÊúÄÈÅ©Âåñ„Åó„Å¶Ëá™‰ø°„ÇíÊåÅ„Å£„Å¶„Éá„Éó„É≠„Ç§„Åß„Åç„Åæ„Åô„ÄÇ\\n\\n3. **„Éá„Éó„É≠„Ç§**: LangGraph„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÁîüÁî£Ê∫ñÂÇô„ÅåÊï¥„Å£„ÅüAPI„ÇÑ„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Å´Â§âÊèõ„Åß„Åç„Åæ„Åô„ÄÇ\\n\\nLangChain„ÅØ„ÄÅ„Åï„Åæ„Åñ„Åæ„Å™„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Å®Áµ±Âêà„Åó„ÄÅÊ®ôÊ∫ñ„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ„ÇíÂÆüË£Ö„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅÈñãÁô∫ËÄÖ„ÅØÁï∞„Å™„Çã„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇíÁ∞°Âçò„Å´Âàá„ÇäÊõø„Åà„Åü„Çä„ÄÅÁµÑ„ÅøÂêà„Çè„Åõ„Åü„Çä„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅLangGraph„Çí‰ΩøÁî®„Åô„Çã„Åì„Å®„Åß„ÄÅË§áÈõë„Å™„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Ç™„Éº„Ç±„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥„ÅåÂèØËÉΩ„Å´„Å™„Çä„Åæ„Åô„ÄÇ„Åï„Çâ„Å´„ÄÅLangSmith„ÇíÂà©Áî®„Åô„Çã„Åì„Å®„Åß„ÄÅ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÂèØË¶ñÂåñ„ÇÑË©ï‰æ°„ÇíË°å„ÅÑ„ÄÅÈñãÁô∫„ÅÆÂäπÁéá„ÇíÂêë‰∏ä„Åï„Åõ„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt = ChatPromptTemplate.from_template('''\\\n",
    "# ‰ª•‰∏ã„ÅÆÊñáËÑà„Å†„Åë„ÇíË∏è„Åæ„Åà„Å¶Ë≥™Âïè„Å´ÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
    "\n",
    "# ÊñáËÑà: \"\"\"\n",
    "# {context}\n",
    "# \"\"\"\n",
    "\n",
    "# Ë≥™Âïè: {question}\n",
    "# ''')\n",
    "\n",
    "hypothetical_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "Ê¨°„ÅÆË≥™Âïè„Å´ÂõûÁ≠î„Åô„Çã‰∏ÄÊñá„ÇíÊõ∏„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
    "\n",
    "Ë≥™Âïè: {question}\n",
    "\"\"\")\n",
    "\n",
    "hypothetical_chain = hypothetical_prompt | model | StrOutputParser()\n",
    "\n",
    "hyde_rag_chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": hypothetical_chain | retriever,\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "\n",
    "hyde_rag_chain.invoke(\"LangChain„ÅÆÊ¶ÇË¶Å„ÇíÊïô„Åà„Å¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ë§áÊï∞„ÅÆÊ§úÁ¥¢„ÇØ„Ç®„É™„ÅÆÁîüÊàê\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LangChain„ÅÆÊ©üËÉΩ‰∏ÄË¶ß', 'LangChain„ÅÆÁâπÂæ¥„Å®Âà©ÁÇπ', 'LangChain„Çí‰ΩøÁî®„Åô„ÇãÁêÜÁî±„Å®„Åù„ÅÆÊ©üËÉΩ']\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class QueryGenerationOutput(BaseModel):\n",
    "    queries: list[str] = Field(..., description=\"Ê§úÁ¥¢„ÇØ„Ç®„É™„ÅÆ„É™„Çπ„Éà\")\n",
    "\n",
    "\n",
    "query_generation_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "Ë≥™Âïè„Å´ÂØæ„Åó„Å¶„Éô„ÇØ„Çø„Éº„Éá„Éº„Çø„Éô„Éº„Çπ„Åã„ÇâÈñ¢ÈÄ£ÊñáÊõ∏„ÇíÊ§úÁ¥¢„Åô„Çã„Åü„ÇÅ„Å´„ÄÅ\n",
    "3„Å§„ÅÆÁï∞„Å™„ÇãÊ§úÁ¥¢„ÇØ„Ç®„É™„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
    "Ë∑ùÈõ¢„Éô„Éº„Çπ„ÅÆÈ°û‰ººÊÄßÊ§úÁ¥¢„ÅÆÈôêÁïå„ÇíÂÖãÊúç„Åô„Çã„Åü„ÇÅ„Å´„ÄÅ\n",
    "„É¶„Éº„Ç∂„Éº„ÅÆË≥™Âïè„Å´ÂØæ„Åó„Å¶Ë§áÊï∞„ÅÆË¶ñÁÇπ„ÇíÊèê‰æõ„Åô„Çã„Åì„Å®„ÅåÁõÆÊ®ô„Åß„Åô„ÄÇ\n",
    "\n",
    "Ë≥™Âïè: {question}\n",
    "\"\"\")\n",
    "\n",
    "query_generation_chain = (\n",
    "    query_generation_prompt\n",
    "    | model.with_structured_output(QueryGenerationOutput)\n",
    "    | (lambda x: x.queries)\n",
    ")\n",
    "\n",
    "question = \"LangChain„ÅÆ‰∏ªË¶Å„Å™Ê©üËÉΩ„ÅØ‰Ωï„Åß„Åô„ÅãÔºü\"\n",
    "\n",
    "queries = query_generation_chain.invoke({\"question\": question})\n",
    "print(queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain„ÅØ„ÄÅÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´ÔºàLLMÔºâ„ÇíÊ¥ªÁî®„Åó„Åü„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÈñãÁô∫„Åô„Çã„Åü„ÇÅ„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Åß„Åô„ÄÇLangChain„ÅØ„ÄÅÈñãÁô∫„ÄÅÈÅãÁî®„ÄÅ„Éá„Éó„É≠„Ç§„ÅÆÂêÑÊÆµÈöé„ÇíÁ∞°Á¥†Âåñ„Åô„Çã„Åì„Å®„ÇíÁõÆÁöÑ„Å®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\n### ‰∏ª„Å™ÁâπÂæ¥\\n1. **Ê®ôÊ∫ñÂåñ„Åï„Çå„Åü„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ**: LangChain„ÅØ„ÄÅ„Åï„Åæ„Åñ„Åæ„Å™AI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Å´ÂøÖË¶Å„Å™„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÅÆÊ®ôÊ∫ñ„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ„ÇíÊèê‰æõ„Åó„ÄÅÁï∞„Å™„Çã„Éó„É≠„Éê„Ç§„ÉÄ„ÉºÈñì„Åß„ÅÆÂàá„ÇäÊõø„Åà„ÇíÂÆπÊòì„Å´„Åó„Åæ„Åô„ÄÇ\\n   \\n2. **„Ç™„Éº„Ç±„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥**: Ë§áÊï∞„ÅÆ„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇÑ„É¢„Éá„É´„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„Å¶Ë§áÈõë„Å™„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊßãÁØâ„Åô„Çã„Åü„ÇÅ„ÅÆÂäπÁéáÁöÑ„Å™Êé•Á∂öÊâãÊÆµ„ÇíÊèê‰æõ„Åó„Åæ„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅË§áÈõë„Å™Âà∂Âæ°„Éï„É≠„Éº„ÇÑ‰∫∫Èñì„ÅÆ‰ªãÂÖ•„ÅåÂøÖË¶Å„Å™„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊßãÁØâ„Åß„Åç„Åæ„Åô„ÄÇ\\n\\n3. **ÂèØË¶≥Ê∏¨ÊÄß„Å®Ë©ï‰æ°**: „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆË§áÈõë„Åï„ÅåÂ¢ó„Åô„Å´„Å§„Çå„Å¶„ÄÅÂÜÖÈÉ®„Åß‰Ωï„ÅåËµ∑„Åì„Å£„Å¶„ÅÑ„Çã„ÅÆ„Åã„ÇíÁêÜËß£„Åô„Çã„Åì„Å®„ÅåÈõ£„Åó„Åè„Å™„Çä„Åæ„Åô„ÄÇLangChain„ÅØ„ÄÅ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÁõ£Ë¶ñ„ÇÑË©ï‰æ°„ÇíÊîØÊè¥„Åó„ÄÅÈñãÁô∫ËÄÖ„ÅåËá™‰ø°„ÇíÊåÅ„Å£„Å¶ËøÖÈÄü„Å´Ë≥™Âïè„Å´Á≠î„Åà„Çâ„Çå„Çã„Çà„ÅÜ„Å´„Åó„Åæ„Åô„ÄÇ\\n\\n### „Ç®„Ç≥„Ç∑„Çπ„ÉÜ„É†\\nLangChain„ÅØ„ÄÅ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„ÅÆ„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇÑ„Çµ„Éº„Éâ„Éë„Éº„ÉÜ„Ç£„ÅÆÁµ±Âêà„ÇíÂà©Áî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊßãÁØâ„Åô„Çã„Åü„ÇÅ„ÅÆÂ§ö„Åè„ÅÆ„ÉÑ„Éº„É´„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅLangGraph„Å®„ÅÑ„ÅÜ„É©„Ç§„Éñ„É©„É™„Çí‰ΩøÁî®„Åó„Å¶„ÄÅÁä∂ÊÖã„ÇíÊåÅ„Å§„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÇíÊßãÁØâ„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇLangSmith„ÅØ„ÄÅ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÁõ£Ë¶ñ„Å®Ë©ï‰æ°„ÇíË°å„ÅÜ„Åü„ÇÅ„ÅÆ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Åß„Åô„ÄÇ\\n\\n„Åì„ÅÆ„Çà„ÅÜ„Å´„ÄÅLangChain„ÅØAI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÈñãÁô∫„ÇíÁ∞°Á¥†Âåñ„Åó„ÄÅÈñãÁô∫ËÄÖ„Åå„Çà„ÇäÂäπÁéáÁöÑ„Å´‰ΩúÊ•≠„Åß„Åç„Çã„Çà„ÅÜ„Å´Ë®≠Ë®à„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_rag_chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": query_generation_chain | retriever.map(),\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "multi_query_rag_chain.invoke({\"question\": \"LangChain„ÅÆÊ¶ÇË¶Å„ÇíÊïô„Åà„Å¶\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Ê§úÁ¥¢Âæå„ÅÆÂ∑•Â§´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Fusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion(\n",
    "    retriever_outputs: list[list[Document]],\n",
    "    k: int = 60,\n",
    ") -> list[str]:\n",
    "    # ÂêÑ„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆ„Ç≥„É≥„ÉÜ„É≥„ÉÑ (ÊñáÂ≠óÂàó) „Å®„Åù„ÅÆ„Çπ„Ç≥„Ç¢„ÅÆÂØæÂøú„Çí‰øùÊåÅ„Åô„ÇãËæûÊõ∏„ÇíÊ∫ñÂÇô\n",
    "    content_score_mapping = {}\n",
    "\n",
    "    # Ê§úÁ¥¢„ÇØ„Ç®„É™„Åî„Å®„Å´„É´„Éº„Éó\n",
    "    for docs in retriever_outputs:\n",
    "        # Ê§úÁ¥¢ÁµêÊûú„ÅÆ„Éâ„Ç≠„É•„É°„É≥„Éà„Åî„Å®„Å´„É´„Éº„Éó\n",
    "        for rank, doc in enumerate(docs):\n",
    "            content = doc.page_content\n",
    "\n",
    "            # Âàù„ÇÅ„Å¶ÁôªÂ†¥„Åó„Åü„Ç≥„É≥„ÉÜ„É≥„ÉÑ„ÅÆÂ†¥Âêà„ÅØ„Çπ„Ç≥„Ç¢„Çí0„ÅßÂàùÊúüÂåñ\n",
    "            if content not in content_score_mapping:\n",
    "                content_score_mapping[content] = 0\n",
    "\n",
    "            # (1 / (È†Ü‰Ωç + k)) „ÅÆ„Çπ„Ç≥„Ç¢„ÇíÂä†ÁÆó\n",
    "            content_score_mapping[content] += 1 / (rank + k)\n",
    "\n",
    "    # „Çπ„Ç≥„Ç¢„ÅÆÂ§ß„Åç„ÅÑÈ†Ü„Å´„ÇΩ„Éº„Éà\n",
    "    ranked = sorted(content_score_mapping.items(), key=lambda x: x[1], reverse=True)  # noqa\n",
    "    return [content for content, _ in ranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain„ÅØ„ÄÅÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´ÔºàLLMÔºâ„ÇíÊ¥ªÁî®„Åó„Åü„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÈñãÁô∫„Åô„Çã„Åü„ÇÅ„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Åß„Åô„ÄÇLangChain„ÅØ„ÄÅÈñãÁô∫„ÄÅÈÅãÁî®„ÄÅ„Éá„Éó„É≠„Ç§„ÅÆÂêÑÊÆµÈöé„ÇíÁ∞°Á¥†Âåñ„Åô„Çã„Åì„Å®„ÇíÁõÆÁöÑ„Å®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\n### ‰∏ª„Å™ÁâπÂæ¥\\n1. **Ê®ôÊ∫ñÂåñ„Åï„Çå„Åü„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ**: LangChain„ÅØ„ÄÅ„Åï„Åæ„Åñ„Åæ„Å™AI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Å´„Åä„Åë„Çã‰∏ªË¶Å„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÅÆ„Åü„ÇÅ„ÅÆÂÖ±ÈÄö„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ„ÇíÊèê‰æõ„Åó„ÄÅÁï∞„Å™„Çã„Éó„É≠„Éê„Ç§„ÉÄ„ÉºÈñì„Åß„ÅÆÂàá„ÇäÊõø„Åà„ÇíÂÆπÊòì„Å´„Åó„Åæ„Åô„ÄÇ\\n   \\n2. **„Ç™„Éº„Ç±„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥**: Ë§áÊï∞„ÅÆ„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇÑ„É¢„Éá„É´„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„Å¶Ë§áÈõë„Å™„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊßãÁØâ„Åô„Çã„Åü„ÇÅ„ÅÆÂäπÁéáÁöÑ„Å™Êé•Á∂ö„Çí„Çµ„Éù„Éº„Éà„Åó„Åæ„Åô„ÄÇLangGraph„Å®„ÅÑ„ÅÜ„É©„Ç§„Éñ„É©„É™„Çí‰ΩøÁî®„Åó„Å¶„ÄÅ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éï„É≠„Éº„Çí„Éé„Éº„Éâ„Å®„Ç®„ÉÉ„Ç∏„ÅÆ„Çª„ÉÉ„Éà„Å®„Åó„Å¶Ë°®Áèæ„Åß„Åç„Åæ„Åô„ÄÇ\\n\\n3. **ÂèØË¶≥Ê∏¨ÊÄß„Å®Ë©ï‰æ°**: LangSmith„Å®„ÅÑ„ÅÜ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„ÇíÈÄö„Åò„Å¶„ÄÅ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„É¢„Éã„Çø„É™„É≥„Ç∞„ÇÑË©ï‰æ°„ÇíË°å„ÅÑ„ÄÅÈñãÁô∫„ÅÆÈÄ≤Êçó„ÇíËøÖÈÄü„Å´ÊääÊè°„Åß„Åç„Çã„Çà„ÅÜ„Å´„Åó„Åæ„Åô„ÄÇ\\n\\n### „Ç≥„É≥„Éù„Éº„Éç„É≥„Éà\\n- **„ÉÅ„É£„ÉÉ„Éà„É¢„Éá„É´**: „É°„ÉÉ„Çª„Éº„Ç∏„ÅÆ„Ç∑„Éº„Ç±„É≥„Çπ„ÇíÂá¶ÁêÜ„Åó„ÄÅÂøúÁ≠î„ÇíÁîüÊàê„Åô„Çã„É¢„Éá„É´„ÄÇ\\n- **„ÉÑ„Éº„É´**: Èñ¢Êï∞„Å®„Åù„ÅÆ„Çπ„Ç≠„Éº„Éû„ÇíÂÆöÁæ©„Åó„ÄÅ„É¢„Éá„É´„ÅåÂ§ñÈÉ®„É™„ÇΩ„Éº„Çπ„Å®ÈÄ£Êê∫„Åß„Åç„Çã„Çà„ÅÜ„Å´„Åó„Åæ„Åô„ÄÇ\\n- **„É™„Éà„É™„Éº„Éê„Éº**: „ÇØ„Ç®„É™„Å´Âü∫„Å•„ÅÑ„Å¶Èñ¢ÈÄ£„Åô„Çã„Éâ„Ç≠„É•„É°„É≥„Éà„ÇíËøî„Åô„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÄÇ\\n\\nLangChain„ÅØ„ÄÅÈñãÁô∫ËÄÖ„ÅåËá™ÂàÜ„ÅÆ„É¶„Éº„Çπ„Ç±„Éº„Çπ„Å´ÊúÄÈÅ©„Å™„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇíÈÅ∏Êäû„Åó„ÄÅÁµÑ„ÅøÂêà„Çè„Åõ„Å¶‰ΩøÁî®„Åß„Åç„ÇãÊüîËªüÊÄß„ÇíÊèê‰æõ„Åó„Åæ„Åô„ÄÇ'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_fusion_chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": query_generation_chain | retriever.map() | reciprocal_rank_fusion,\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "rag_fusion_chain.invoke(\"LangChain„ÅÆÊ¶ÇË¶Å„ÇíÊïô„Åà„Å¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohere „ÅÆ„É™„É©„É≥„ÇØ„É¢„Éá„É´„Çí‰ΩøÁî®„Åô„ÇãÊ∫ñÂÇô\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"COHERE_API_KEY\"] = os.getenv(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-cohere==0.3.0\n",
      "  Using cached langchain_cohere-0.3.0-py3-none-any.whl (43 kB)\n",
      "Collecting tabulate<0.10.0,>=0.9.0\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting langchain-experimental>=0.3.0\n",
      "  Using cached langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-cohere==0.3.0) (2.10.6)\n",
      "Collecting pandas>=1.4.3\n",
      "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Collecting cohere<6.0,>=5.5.6\n",
      "  Downloading cohere-5.14.0-py3-none-any.whl (253 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-core<0.4,>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-cohere==0.3.0) (0.3.0)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (2.27.2)\n",
      "Collecting httpx-sse==0.4.0\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (4.12.2)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (0.28.1)\n",
      "Collecting fastavro<2.0.0,>=1.9.4\n",
      "  Using cached fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (0.20.3)\n",
      "Collecting types-requests<3.0.0,>=2.0.0\n",
      "  Downloading types_requests-2.32.0.20250306-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere==0.3.0) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere==0.3.0) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere==0.3.0) (24.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere==0.3.0) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (0.3.0)\n",
      "Collecting langchain-core<0.4,>=0.3.0\n",
      "  Using cached langchain_core-0.3.45-py3-none-any.whl (415 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pandas>=1.4.3->langchain-cohere==0.3.0) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pandas>=1.4.3->langchain-cohere==0.3.0) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic<3,>=2->langchain-cohere==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: idna in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (3.10)\n",
      "Requirement already satisfied: anyio in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-cohere==0.3.0) (3.0.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (3.11.13)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (2.0.39)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (0.3.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (2.8.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (0.6.7)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain-cohere==0.3.0) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain-cohere==0.3.0) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain-cohere==0.3.0) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (3.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (0.29.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (25.3.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (4.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (1.18.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (0.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (1.3.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (0.9.0)\n",
      "Requirement already satisfied: filelock in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (2025.3.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (4.67.1)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (0.3.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (1.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (3.1.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere==0.3.0) (1.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere==0.3.0) (1.0.0)\n",
      "Installing collected packages: pytz, tzdata, types-requests, tabulate, httpx-sse, fastavro, pandas, langchain-core, cohere, langchain-experimental, langchain-cohere\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.0\n",
      "    Uninstalling langchain-core-0.3.0:\n",
      "      Successfully uninstalled langchain-core-0.3.0\n",
      "Successfully installed cohere-5.14.0 fastavro-1.10.0 httpx-sse-0.4.0 langchain-cohere-0.3.0 langchain-core-0.3.45 langchain-experimental-0.3.4 pandas-2.2.3 pytz-2025.1 tabulate-0.9.0 types-requests-2.32.0.20250306 tzdata-2025.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-cohere==0.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohere „ÅÆ„É™„É©„É≥„ÇØ„É¢„Éá„É´„ÅÆÂ∞éÂÖ•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='‰ª•‰∏ã„ÅÆÊñáËÑà„Å†„Åë„ÇíË∏è„Åæ„Åà„Å¶Ë≥™Âïè„Å´ÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\n\\nÊñáËÑà: \"\"\"\\n{context}\\n\"\"\"\\n\\nË≥™Âïè: {question}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain„ÅØ„ÄÅÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´ÔºàLLMÔºâ„ÇíÊ¥ªÁî®„Åó„Åü„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÈñãÁô∫„Åô„Çã„Åü„ÇÅ„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Åß„Åô„ÄÇ„Åì„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅØ„ÄÅLLM„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„É©„Ç§„Éï„Çµ„Ç§„ÇØ„É´„ÅÆÂêÑ„Çπ„ÉÜ„Éº„Ç∏„ÇíÁ∞°Á¥†Âåñ„Åó„Åæ„Åô„ÄÇÂÖ∑‰ΩìÁöÑ„Å´„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™Ê©üËÉΩ„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\\n\\n1. **ÈñãÁô∫**: LangChain„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇÑ„Çµ„Éº„Éâ„Éë„Éº„ÉÜ„Ç£„ÅÆÁµ±Âêà„Çí‰ΩøÁî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊßãÁØâ„Åß„Åç„Åæ„Åô„ÄÇLangGraph„ÇíÂà©Áî®„Åô„Çã„Åì„Å®„Åß„ÄÅÁä∂ÊÖã„ÇíÊåÅ„Å§„Ç®„Éº„Ç∏„Çß„É≥„Éà„Çí‰ΩúÊàê„Åó„ÄÅ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„ÇÑ‰∫∫Èñì„ÅÆ‰ªãÂÖ•„Çí„Çµ„Éù„Éº„Éà„Åó„Åæ„Åô„ÄÇ\\n\\n2. **ÁîüÁî£Âåñ**: LangSmith„Çí‰ΩøÁî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊ§úÊüª„ÄÅÁõ£Ë¶ñ„ÄÅË©ï‰æ°„Åó„ÄÅÁ∂ôÁ∂öÁöÑ„Å´ÊúÄÈÅ©Âåñ„Åó„Å¶Ëá™‰ø°„ÇíÊåÅ„Å£„Å¶„Éá„Éó„É≠„Ç§„Åß„Åç„Åæ„Åô„ÄÇ\\n\\n3. **„Éá„Éó„É≠„Ç§**: LangGraph„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÁîüÁî£Ê∫ñÂÇô„ÅåÊï¥„Å£„ÅüAPI„ÇÑ„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Å´Â§âÊèõ„Åß„Åç„Åæ„Åô„ÄÇ\\n\\nLangChain„ÅØ„ÄÅ„ÉÅ„É£„ÉÉ„Éà„É¢„Éá„É´„ÇÑÂüã„ÇÅËæº„Åø„É¢„Éá„É´„ÄÅ„Éô„ÇØ„Éà„É´„Çπ„Éà„Ç¢„Å™„Å©„ÅÆÈñ¢ÈÄ£ÊäÄË°ì„Å´ÂØæ„Åô„ÇãÊ®ôÊ∫ñ„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ„ÇíÂÆüË£Ö„Åó„Å¶„Åä„Çä„ÄÅÊï∞Áôæ„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Å®Áµ±Âêà„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅË§áÊï∞„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„É©„Ç§„Éñ„É©„É™„ÅßÊßãÊàê„Åï„Çå„Å¶„Åä„Çä„ÄÅÈñãÁô∫ËÄÖ„ÅØÂøÖË¶Å„Å™„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇíÈÅ∏Êäû„Åó„Å¶‰ΩøÁî®„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def rerank(inp: dict[str, Any], top_n: int = 3) -> list[Document]:\n",
    "    question = inp[\"question\"]\n",
    "    documents = inp[\"documents\"]\n",
    "\n",
    "    cohere_reranker = CohereRerank(model=\"rerank-multilingual-v3.0\", top_n=top_n)\n",
    "    return cohere_reranker.compress_documents(documents=documents, query=question)\n",
    "\n",
    "\n",
    "rerank_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"documents\": retriever,\n",
    "    }\n",
    "    | RunnablePassthrough.assign(context=rerank)\n",
    "    | prompt | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "rerank_rag_chain.invoke(\"LangChain„ÅÆÊ¶ÇË¶Å„ÇíÊïô„Åà„Å¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. Ë§áÊï∞„ÅÆ Retriever „Çí‰Ωø„ÅÜÂ∑•Â§´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM „Å´„Çà„Çã„É´„Éº„ÉÜ„Ç£„É≥„Ç∞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "\n",
    "langchain_document_retriever = retriever.with_config(\n",
    "    {\"run_name\": \"langchain_document_retriever\"}\n",
    ")\n",
    "\n",
    "web_retriever = TavilySearchAPIRetriever(k=3).with_config(\n",
    "    {\"run_name\": \"web_retriever\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Route(str, Enum):\n",
    "    langchain_document = \"langchain_document\"\n",
    "    web = \"web\"\n",
    "\n",
    "\n",
    "class RouteOutput(BaseModel):\n",
    "    route: Route\n",
    "\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "Ë≥™Âïè„Å´ÂõûÁ≠î„Åô„Çã„Åü„ÇÅ„Å´ÈÅ©Âàá„Å™Retriever„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
    "\n",
    "Ë≥™Âïè: {question}\n",
    "\"\"\")\n",
    "\n",
    "route_chain = (\n",
    "    route_prompt\n",
    "    | model.with_structured_output(RouteOutput)\n",
    "    | (lambda x: x.route)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routed_retriever(inp: dict[str, Any]) -> list[Document]:\n",
    "    question = inp[\"question\"]\n",
    "    route = inp[\"route\"]\n",
    "\n",
    "    if route == Route.langchain_document:\n",
    "        return langchain_document_retriever.invoke(question)\n",
    "    elif route == Route.web:\n",
    "        return web_retriever.invoke(question)\n",
    "\n",
    "    raise ValueError(f\"Unknown retriever: {retriever}\")\n",
    "\n",
    "\n",
    "route_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"route\": route_chain,\n",
    "    }\n",
    "    | RunnablePassthrough.assign(context=routed_retriever)\n",
    "    | prompt | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain„ÅØ„ÄÅÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´ÔºàLLMÔºâ„ÇíÊ¥ªÁî®„Åó„Åü„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÈñãÁô∫„Åô„Çã„Åü„ÇÅ„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Åß„Åô„ÄÇ„Åì„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅØ„ÄÅLLM„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„É©„Ç§„Éï„Çµ„Ç§„ÇØ„É´„ÅÆÂêÑ„Çπ„ÉÜ„Éº„Ç∏„ÇíÁ∞°Á¥†Âåñ„Åó„Åæ„Åô„ÄÇÂÖ∑‰ΩìÁöÑ„Å´„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™Ê©üËÉΩ„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n\\n1. **ÈñãÁô∫**: LangChain„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇÑ„Çµ„Éº„Éâ„Éë„Éº„ÉÜ„Ç£Áµ±Âêà„Çí‰ΩøÁî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊßãÁØâ„Åß„Åç„Åæ„Åô„ÄÇLangGraph„ÇíÂà©Áî®„Åô„Çã„Åì„Å®„Åß„ÄÅÁä∂ÊÖã„ÇíÊåÅ„Å§„Ç®„Éº„Ç∏„Çß„É≥„Éà„Çí‰ΩúÊàê„Åó„ÄÅ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„ÇÑ‰∫∫Èñì„ÅÆ‰ªãÂÖ•„Çí„Çµ„Éù„Éº„Éà„Åó„Åæ„Åô„ÄÇ\\n\\n2. **ÁîüÁî£Âåñ**: LangSmith„Çí‰ΩøÁî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊ§úÊüª„ÄÅÁõ£Ë¶ñ„ÄÅË©ï‰æ°„Åó„ÄÅÁ∂ôÁ∂öÁöÑ„Å´ÊúÄÈÅ©Âåñ„Åó„Å¶Ëá™‰ø°„ÇíÊåÅ„Å£„Å¶„Éá„Éó„É≠„Ç§„Åß„Åç„Åæ„Åô„ÄÇ\\n\\n3. **„Éá„Éó„É≠„Ç§**: LangGraph„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÁîüÁî£Ê∫ñÂÇô„ÅåÊï¥„Å£„ÅüAPI„ÇÑ„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Å´Â§âÊèõ„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ\\n\\nLangChain„ÅØ„ÄÅLLM„ÇÑÈñ¢ÈÄ£ÊäÄË°ìÔºàÂüã„ÇÅËæº„Åø„É¢„Éá„É´„ÇÑ„Éô„ÇØ„Éà„É´„Çπ„Éà„Ç¢Ôºâ„Å´ÂØæ„Åô„ÇãÊ®ôÊ∫ñ„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ„ÇíÂÆüË£Ö„Åó„ÄÅÊï∞Áôæ„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Å®Áµ±Âêà„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅË§áÊï∞„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„É©„Ç§„Éñ„É©„É™„ÅßÊßãÊàê„Åï„Çå„Å¶„Åä„Çä„ÄÅ„É¶„Éº„Ç∂„Éº„ÅØËá™ÂàÜ„ÅÆ„Éã„Éº„Ç∫„Å´Âøú„Åò„Å¶„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇíÈÅ∏Êäû„Åó„Å¶‰ΩøÁî®„Åß„Åç„Åæ„Åô„ÄÇ'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_rag_chain.invoke(\"LangChain„ÅÆÊ¶ÇË¶Å„ÇíÊïô„Åà„Å¶\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Êù±‰∫¨„ÅÆ‰ªäÊó•„ÄÅ2Êúà8Êó•ÔºàÂúüÔºâ„ÅÆÂ§©Ê∞ó„ÅØÊô¥„Çå„Åß„ÄÅÊúÄÈ´òÊ∞óÊ∏©„ÅØ9‚ÑÉ„ÄÅÊúÄ‰ΩéÊ∞óÊ∏©„ÅØ-1‚ÑÉ„Åß„Åô„ÄÇÈôçÊ∞¥Á¢∫Áéá„ÅØ10%„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂåóË•ø„ÅÆÈ¢®„Åå„ÇÑ„ÇÑÂº∑„ÅèÂêπ„Åè‰∫àÊÉ≥„Åß„Åô„ÄÇ'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_rag_chain.invoke(\"Êù±‰∫¨„ÅÆ‰ªäÊó•„ÅÆÂ§©Ê∞ó„ÅØÔºü\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### „Éè„Ç§„Éñ„É™„ÉÉ„ÉâÊ§úÁ¥¢„ÅÆÂÆüË£Ö\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25==0.2.2 in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /home/rmasuda/agent-book-dev/venv/lib/python3.10/site-packages (from rank-bm25==0.2.2) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rank-bm25==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "chroma_retriever = retriever.with_config(\n",
    "    {\"run_name\": \"chroma_retriever\"}\n",
    ")\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents).with_config(\n",
    "    {\"run_name\": \"bm25_retriever\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "hybrid_retriever = (\n",
    "    RunnableParallel({\n",
    "        \"chroma_documents\": chroma_retriever,\n",
    "        \"bm25_documents\": bm25_retriever,\n",
    "    })\n",
    "    | (lambda x: [x[\"chroma_documents\"], x[\"bm25_documents\"]])\n",
    "    | reciprocal_rank_fusion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain„ÅØ„ÄÅÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´ÔºàLLMÔºâ„ÇíÊ¥ªÁî®„Åó„Åü„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÈñãÁô∫„Åô„Çã„Åü„ÇÅ„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Åß„Åô„ÄÇ„Åì„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅØ„ÄÅLLM„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„É©„Ç§„Éï„Çµ„Ç§„ÇØ„É´„ÅÆÂêÑÊÆµÈöé„ÇíÁ∞°Á¥†Âåñ„Åó„Åæ„Åô„ÄÇÂÖ∑‰ΩìÁöÑ„Å´„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™Ê©üËÉΩ„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\\n\\n1. **ÈñãÁô∫**: LangChain„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇÑ„Çµ„Éº„Éâ„Éë„Éº„ÉÜ„Ç£„ÅÆÁµ±Âêà„Çí‰ΩøÁî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊßãÁØâ„Åß„Åç„Åæ„Åô„ÄÇLangGraph„ÇíÂà©Áî®„Åô„Çã„Åì„Å®„Åß„ÄÅÁä∂ÊÖã„ÇíÊåÅ„Å§„Ç®„Éº„Ç∏„Çß„É≥„Éà„Çí‰ΩúÊàê„Åó„ÄÅ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„ÇÑ‰∫∫Èñì„ÅÆ‰ªãÂÖ•„Çí„Çµ„Éù„Éº„Éà„Åó„Åæ„Åô„ÄÇ\\n\\n2. **ÁîüÁî£Âåñ**: LangSmith„Çí‰ΩøÁî®„Åó„Å¶„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÊ§úÊüª„ÄÅÁõ£Ë¶ñ„ÄÅË©ï‰æ°„Åó„ÄÅÁ∂ôÁ∂öÁöÑ„Å´ÊúÄÈÅ©Âåñ„Åó„Å¶Ëá™‰ø°„ÇíÊåÅ„Å£„Å¶„Éá„Éó„É≠„Ç§„Åß„Åç„Åæ„Åô„ÄÇ\\n\\n3. **„Éá„Éó„É≠„Ç§**: LangGraph„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÁîüÁî£Ê∫ñÂÇô„ÅåÊï¥„Å£„ÅüAPI„ÇÑ„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Å´Â§âÊèõ„Åß„Åç„Åæ„Åô„ÄÇ\\n\\nLangChain„ÅØ„ÄÅLLM„ÇÑÈñ¢ÈÄ£ÊäÄË°ìÔºàÂüã„ÇÅËæº„Åø„É¢„Éá„É´„ÇÑ„Éô„ÇØ„Çø„Éº„Çπ„Éà„Ç¢„Å™„Å©Ôºâ„Å´ÂØæ„Åô„ÇãÊ®ôÊ∫ñ„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ„ÇíÂÆüË£Ö„Åó„Å¶„Åä„Çä„ÄÅÊï∞Áôæ„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Å®Áµ±Âêà„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅË§áÊï∞„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„É©„Ç§„Éñ„É©„É™„ÅßÊßãÊàê„Åï„Çå„Å¶„Åä„Çä„ÄÅ„É¶„Éº„Ç∂„Éº„ÅØÂøÖË¶Å„Å´Âøú„Åò„Å¶„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÇíÈÅ∏Êäû„Åó„Å¶‰ΩøÁî®„Åß„Åç„Åæ„Åô„ÄÇ'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": hybrid_retriever,\n",
    "    }\n",
    "    | prompt | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "hybrid_rag_chain.invoke(\"LangChain„ÅÆÊ¶ÇË¶Å„ÇíÊïô„Åà„Å¶\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
